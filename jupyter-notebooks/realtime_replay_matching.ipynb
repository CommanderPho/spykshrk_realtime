{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sys\n",
    "import os.path\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore',invalid='ignore')\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import text\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from spykshrk.realtime.datatypes import Datatypes\n",
    "import loren_frank_data_processing as lfdp\n",
    "from loren_frank_data_processing import Animal\n",
    "import trodes2SS\n",
    "import scipy as sp\n",
    "import sungod_util\n",
    "from spykshrk.franklab.data_containers import RippleTimes, pos_col_format#FlatLinearPosition, SpikeFeatures, Posteriors, \\\n",
    "         #EncodeSettings, pos_col_format, SpikeObservation, RippleTimes, DayEpochEvent, DayEpochTimeSeries\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to start up holoviews\n",
    "import holoviews as hv\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to test and make sure holoviews and bokeh are working\n",
    "coords = np.random.rand(50,2)\n",
    "points = hv.Points(coords)\n",
    "\n",
    "points.opts(color='k', marker='+', size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to read real-time hdf5 file\n",
    "\n",
    "#12-17, bill run session 3\n",
    "#hdf_file = '/stelmo/mcoulter/spykshrk_output/bill/20191217_bill_05_r3_westerlies_streaming.rec_merged.h5'\n",
    "\n",
    "# new pos/vel and fix prob no spike\n",
    "hdf_file = '/stelmo/mcoulter/spykshrk_output_westerlies/remy_decoder_19tet_2_13_prob_no.rec_merged.h5'\n",
    "\n",
    "store = pd.HDFStore(hdf_file, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check new ripple numbering\n",
    "encoder_data3 = store['rec_3']\n",
    "decoder_data3 = store['rec_4']\n",
    "decoder_missed_spikes3 = store['rec_5']\n",
    "likelihood_data3 = store['rec_6']\n",
    "occupancy_data3 = store['rec_7']\n",
    "ripple_data3 = store['rec_1']\n",
    "#stim_state = store['rec_10']\n",
    "stim_lockout3 = store['rec_11']\n",
    "stim_message3 = store['rec_12']\n",
    "timing3 = store['rec_100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_ind</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time</th>\n",
       "      <th>lockout_num</th>\n",
       "      <th>lockout_state</th>\n",
       "      <th>tets_above_thresh</th>\n",
       "      <th>big_rip_message_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>39709760</td>\n",
       "      <td>4.418515e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>39711280</td>\n",
       "      <td>1.581650e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>39750980</td>\n",
       "      <td>1.181869e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181</td>\n",
       "      <td>39752500</td>\n",
       "      <td>1.581650e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433</td>\n",
       "      <td>39852760</td>\n",
       "      <td>9.304432e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>368727</td>\n",
       "      <td>162004040</td>\n",
       "      <td>1.581654e+09</td>\n",
       "      <td>692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>368741</td>\n",
       "      <td>162007040</td>\n",
       "      <td>1.581654e+09</td>\n",
       "      <td>692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>368857</td>\n",
       "      <td>162028160</td>\n",
       "      <td>3.088275e+00</td>\n",
       "      <td>693</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>368877</td>\n",
       "      <td>162029680</td>\n",
       "      <td>1.581654e+09</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>368887</td>\n",
       "      <td>162032680</td>\n",
       "      <td>1.581654e+09</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2067 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rec_ind  timestamp          time  lockout_num  lockout_state  tets_above_thresh  big_rip_message_sent\n",
       "0          71   39709760  4.418515e+00            0              1                  2                     1\n",
       "1          76   39711280  1.581650e+09            0              0                  0                     1\n",
       "2         176   39750980  1.181869e+00            1              1                  2                     1\n",
       "3         181   39752500  1.581650e+09            1              0                  0                     1\n",
       "4         433   39852760  9.304432e-01            2              1                  2                     1\n",
       "...       ...        ...           ...          ...            ...                ...                   ...\n",
       "2062   368727  162004040  1.581654e+09          692              0                  0                     0\n",
       "2063   368741  162007040  1.581654e+09          692              0                  0                     0\n",
       "2064   368857  162028160  3.088275e+00          693              1                  2                     0\n",
       "2065   368877  162029680  1.581654e+09          693              0                  0                     0\n",
       "2066   368887  162032680  1.581654e+09          693              0                  0                     0\n",
       "\n",
       "[2067 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_lockout3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the most recent offline decode\n",
    "file_path = '/stelmo/mcoulter/oct_2019_decoding/remy_20_2_shuffle_0_posteriors_functionalized_150_decode_whole.h5'\n",
    "hdf_base = '/analysis'\n",
    "hdf_grps = 'decode/clusterless/offline/posterior'\n",
    "hdf_label = 'sungod_trans_mat'\n",
    "\n",
    "with pd.HDFStore(file_path, 'r') as store:\n",
    "    main_path = os.path.join(hdf_base, hdf_grps, hdf_label)\n",
    "    posteriors2 = store[main_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linearization found. Loading it\n",
      "[  0.   5.  10.  15.  20.  25.  30.  35.  40.  45.  50.  55.  60.  64.\n",
      "  69.  74.  79.  84.  89.  94.  99. 104. 109. 114. 119. 124. 129. 134.\n",
      " 139. 144. 147. 152. 157. 162. 167. 172. 177. 182. 187. 192. 197. 202.\n",
      " 207. 212. 217. 222. 227. 232. 237. 242. 247. 252. 257. 262. 267. 272.\n",
      " 277. 282. 287. 292. 297. 302. 307. 312. 317. 319. 324. 329. 334. 339.\n",
      " 344. 349. 354. 359. 364. 369. 374. 379. 384. 389. 394. 399. 403. 408.\n",
      " 413. 418. 423. 428. 433. 438. 443. 448. 453. 458. 463. 468. 473. 478.\n",
      " 483. 485. 490. 495. 500. 505. 510. 515. 520. 525. 530. 535. 540. 545.\n",
      " 550. 555. 560. 565. 568. 573. 578. 583. 588. 593. 598. 603. 608. 613.\n",
      " 618. 623. 628. 633. 638. 643. 648. 649. 654. 659. 664. 669. 674. 679.\n",
      " 684. 689. 694. 699. 704. 709. 714.]\n",
      "[[  0   8]\n",
      " [ 13  25]\n",
      " [ 30  42]\n",
      " [ 47  59]\n",
      " [ 65  77]\n",
      " [ 82  94]\n",
      " [ 99 111]\n",
      " [116 128]\n",
      " [133 145]]\n",
      "Rips less than velocity thresh: 1256\n"
     ]
    }
   ],
   "source": [
    "# get linear position for offline\n",
    "#### Define parameters\n",
    "rat_name = 'remy'\n",
    "day =  20     #previously:{'remy':[20], 'gus':[28], 'bernard':[23], 'fievel':[19]}\n",
    "epoch = 2   # previously:{'remy':[4], 'gus':[2], 'bernard':[4], 'fievel':[2]} \n",
    "\n",
    "# define data source filepaths\n",
    "path_base = '/stelmo/mcoulter/'\n",
    "#path_base = '/mnt/vortex/mcoulter/'\n",
    "raw_directory = path_base + 'raw_data/' + rat_name + '/'\n",
    "linearization_path = path_base + 'maze_info/'\n",
    "day_ep = str(day) + '_' + str(epoch)\n",
    "\n",
    "#tetlist = None\n",
    "tetlist = [4]\n",
    "tetrodes= tetlist\n",
    "\n",
    "pos_bin_size = 5\n",
    "velocity_thresh_for_enc_dec = 4\n",
    "velocity_buffer = 0\n",
    "shift_amt_for_shuffle = 0\n",
    "use_enc_as_dec = 1   #if you want to use the encoding marks as the decoding marks\n",
    "discrete_tm_val=.99   # for classifier\n",
    "\n",
    "# IMPORT and process data\n",
    "#initialize data importer\n",
    "datasrc = trodes2SS.TrodesImport(raw_directory, rat_name, [day], \n",
    "                       [epoch], tetrodes)\n",
    "# Import trials\n",
    "trials = datasrc.import_trials()\n",
    "# Import raw position\n",
    "linear_pos_raw = datasrc.import_pos(xy='x')   # this is basically just to pull in speed, will be replaced with linearized below\n",
    "#posY = datasrc.import_pos(xy='y')          #  OPTIONAL; useful for 2d visualization\n",
    "\n",
    "# if linearization exists, load it. if not, run the linearization.\n",
    "lin_output1 = linearization_path + rat_name + '/' + rat_name + '_' + day_ep + '_' + 'linearized_distance.npy'\n",
    "lin_output2 = linearization_path + rat_name + '/' + rat_name + '_' + day_ep + '_' + 'linearized_track_segments.npy'\n",
    "linear_pos_raw['linpos_flat'] = np.load(lin_output1)   #replace x pos with linerized \n",
    "track_segment_ids = np.load(lin_output2)\n",
    "print('Linearization found. Loading it')\n",
    "\n",
    "#if os.path.exists(lin_output1) == False:\n",
    "#    print('Linearization result doesnt exist. Doing linearization calculation')\n",
    "#    sungod_util.run_linearization_routine(rat_name, day, epoch, linearization_path, raw_directory, gap_size=20)\n",
    "#    linear_pos_raw['linpos_flat'] = np.load(lin_output1)\n",
    "#    track_segment_ids = np.load(lin_output2)\n",
    "#else: \n",
    "\n",
    "# generate boundary definitions of each segment\n",
    "arm_coords, _ = sungod_util.define_segment_coordinates(linear_pos_raw, track_segment_ids)  # optional addition output of all occupied positions (not just bounds)\n",
    "\n",
    "#bin linear position \n",
    "binned_linear_pos, binned_arm_coords, pos_bins = sungod_util.bin_position_data(linear_pos_raw, arm_coords, pos_bin_size)\n",
    "\n",
    "# Import ripples\n",
    "rips_tmp = datasrc.import_rips(linear_pos_raw, velthresh=4) \n",
    "rips = RippleTimes.create_default(rips_tmp,1)  # cast to rippletimes obj\n",
    "print('Rips less than velocity thresh: '+str(len(rips)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge posteriors and ripples for realtime data\n",
    "\n",
    "# want to try to add both beginning of ripple and time bin when message was sent to decoder_data\n",
    "# for stim_message this merge ('nearest') put the arm number and ripple number at all timebins after the end of the rippple\n",
    "# for stim_lockout this merge ('backward') will highlight the ripple time\n",
    "stim_message_1 = stim_message3.copy()\n",
    "stim_message_2 = stim_message_1.drop(['rec_ind','spike_timestamp','lfp_timestamp','time',\n",
    "                                   'ripple_time_bin','spike_count','delay',\n",
    "                                   'content_threshold','max_arm_repeats','box','arm1','arm2',\n",
    "                                   'arm3','arm4','arm5','arm6','arm7','arm8'], axis=1)\n",
    "stim_message_2\n",
    "decode_to_merge = decoder_data3.copy()\n",
    "merged_decoder_stim = pd.merge_asof(decode_to_merge,stim_message_2,on='bin_timestamp',direction='nearest')\n",
    "merged_decoder_stim\n",
    "\n",
    "stim_lockout_1 = stim_lockout3.copy()\n",
    "stim_lockout_1['bin_timestamp'] = stim_lockout3['timestamp']\n",
    "stim_lockout_2 = stim_lockout_1.drop(['rec_ind','timestamp','time','lockout_num','tets_above_thresh',\n",
    "                                      'big_rip_message_sent'], axis=1)\n",
    "stim_lockout_2\n",
    "##decode_to_merge = decoder_data1.copy()\n",
    "merged_decoder_lockout = pd.merge_asof(merged_decoder_stim,stim_lockout_2,on='bin_timestamp',direction='backward')\n",
    "merged_decoder_lockout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_decoder_lockout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5e0ea3762b29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print(timestamp-30*300,timestamp+30*300)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#posterior from decode/stim message merged table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         merged_to_plot = merged_decoder_lockout[(merged_decoder_lockout['bin_timestamp'] > timestamp-30*300) & \n\u001b[0m\u001b[1;32m     17\u001b[0m                                             (merged_decoder_lockout['bin_timestamp'] < timestamp+30*300)]\n\u001b[1;32m     18\u001b[0m         \u001b[0mmerged_to_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bin_timestamp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merged_decoder_lockout' is not defined"
     ]
    }
   ],
   "source": [
    "# subset of decoder_data to plot - loop through each ripple\n",
    "# how can we just generate the images for the mismatched ripples??\n",
    "\n",
    "realtime_posterior_sum_all = np.zeros((len(stim_lockout3[stim_lockout3['lockout_state']==1]),4))\n",
    "counter = -1\n",
    "summarize_all_rips = True\n",
    "\n",
    "for timestamp in stim_lockout3[stim_lockout3['lockout_state']==1]['timestamp'][0:10].values:\n",
    "    #counter += 1\n",
    "    ##print(counter)\n",
    "    #if counter in non_matching['realtime_rip'].values:\n",
    "    #    print(counter)\n",
    "    if summarize_all_rips:\n",
    "    #print(timestamp-30*300,timestamp+30*300)\n",
    "    #posterior from decode/stim message merged table\n",
    "        merged_to_plot = merged_decoder_lockout[(merged_decoder_lockout['bin_timestamp'] > timestamp-30*300) & \n",
    "                                            (merged_decoder_lockout['bin_timestamp'] < timestamp+30*300)]\n",
    "        merged_to_plot.set_index('bin_timestamp',inplace=True)\n",
    "\n",
    "        posterior_only_merged = merged_to_plot.drop(['rec_ind','wall_time','velocity','real_pos',\n",
    "                                                'spike_count','ripple','ripple_length','timestamp_shift',\n",
    "                                                'shortcut_message','box','arm1','arm2','arm3','arm4','arm5',\n",
    "                                                'arm6','arm7','arm8','posterior_max_arm','shortcut_message_sent',\n",
    "                                                'raw_x','raw_y','smooth_x','smooth_y','ripple_number_x',\n",
    "                                                'ripple_number_y','ripple_end','lockout_state','lockout_num',\n",
    "                                                'delay','next_bin'], axis=1)\n",
    "        # ripple time - generated from lockout_state\n",
    "        # lockout_state changes at posterior_lock end, so this should post_lock (now 50 msec)\n",
    "        ripples_to_plot = merged_to_plot.reset_index()\n",
    "        ripple_times_rt = ripples_to_plot.index[ripples_to_plot['lockout_state'] > 0].tolist()\n",
    "\n",
    "        # get timestamp when shortcut message was sent - try to just isolate single ripple\n",
    "        # bin_timestamp will show the delay - it will appear before the start of the ripple\n",
    "        # in contrast, lfp_timestamp would line up exactly with ripple start\n",
    "        shortcut_message_to_plot = stim_message3[(stim_message3['bin_timestamp'] > timestamp-30*30) & \n",
    "                                             (stim_message3['bin_timestamp'] < timestamp+30*100)]\n",
    "        merged_to_plot_index = merged_to_plot.reset_index()\n",
    "        # loop through multiple entries in shortcut_message\n",
    "        shortcut_message_times = np.zeros(shortcut_message_to_plot.shape[0])\n",
    "        for i in np.arange(0,shortcut_message_to_plot.shape[0]):\n",
    "            shortcut_message_times[i] = merged_to_plot_index.index[merged_to_plot_index['bin_timestamp'].values == shortcut_message_to_plot['bin_timestamp'][i:i+1].values].tolist()[0]\n",
    "        #shortcut_message_times = merged_to_plot_index.index[merged_to_plot_index['bin_timestamp'].values == shortcut_message_to_plot['bin_timestamp'].values].tolist()\n",
    "        shortcut_messages = shortcut_message_to_plot['shortcut_message_sent'].values*123\n",
    "    \n",
    "        #posterior_only\n",
    "        #print(posterior_only_merged.shape)\n",
    "    \n",
    "        #plot heatmap with posterior surrounding each ripple\n",
    "        post_heatmap = posterior_only_merged.transpose()\n",
    "        post_heatmap = post_heatmap.iloc[::-1]\n",
    "    \n",
    "        #plot title: include ripple number, max arm, and delay\n",
    "        title_index = int(len(merged_to_plot)*0.6)\n",
    "        max_arm = merged_to_plot[title_index:title_index+1]['posterior_max_arm'].values\n",
    "        #ripple_num = merged_to_plot[-2:-1]['ripple_number_y'].values\n",
    "        #f'Real-time posterior, ripple {max_arm}. Max arm {ripple_num}'\n",
    "        #ripple_num = merged_to_plot[ripple_num_index:ripple_num_index+1]['ripple_number_y'].values\n",
    "        ripple_num = merged_to_plot[title_index:title_index+1]['lockout_num'].values\n",
    "        message_delay = np.around(merged_to_plot[title_index:title_index+1]['delay'].values,decimals=0)\n",
    "\n",
    "        # fill in current row of posterior sum array - seems to work\n",
    "        realtime_posterior_sum_all[counter,0] = ripple_num\n",
    "        realtime_posterior_sum_all[counter,1] = max_arm\n",
    "        realtime_posterior_sum_all[counter,2] = shortcut_message_to_plot.shape[0]-1\n",
    "        realtime_posterior_sum_all[counter,3] = message_delay\n",
    "    \n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.title(f'Real-time posterior, Ripple {ripple_num} Max arm {max_arm} Delay {message_delay}')\n",
    "        ax = (sns.heatmap(post_heatmap,vmin=0, vmax=0.7))\n",
    "        #gap lines need to be inverse of where you would expect\n",
    "        ax.hlines([135-9,135-25,135-41,135-57,135-73,135-89,135-105,135-121], lw=2, color='w',*ax.get_xlim())\n",
    "        ax.scatter(np.arange(0,merged_to_plot.shape[0]),136-merged_to_plot['real_pos'].values,s=1,alpha=0.5,color='cyan')\n",
    "        #ax.scatter(stim_lockout['timestamp'].values,(stim_lockout['lockout_state'].values)*50,s=2,alpha=1)\n",
    "        ax.vlines(ripple_times_rt,lw=1,color='w',alpha=0.3,*ax.get_ylim())\n",
    "        # plot time when statescript message was sent, 100 = sent, 0 = not send\n",
    "        # if X is missing it means the timestamp didn't match perfectly above\n",
    "        # could take delay into account here: add delay/5\n",
    "        ax.scatter(shortcut_message_times+message_delay/5,124-shortcut_messages,s=40,color='yellow',marker='x')\n",
    "\n",
    "        # try to find ripple number\n",
    "        #ax.scatter(np.arange(0,merged_to_plot.shape[0]),136-merged_to_plot['ripple_number_y'].values+20,s=1,alpha=0.5,color='red')\n",
    "        # need to convert sent_message_list into values starting where beginning of this plot is x=0\n",
    "        #ax.vlines(100,lw=1,color='w',alpha=1,*ax.get_ylim())\n",
    "    \n",
    "        # final step: save the figure\n",
    "        #plt.savefig(f'/stelmo/mcoulter/posterior_plots_by_ripple/2-4-20/remy_20_2_realtime_2_5_nonmatching_{ripple_num}_timestamp_{timestamp}.jpg')\n",
    "\n",
    "# convert offline_posterior_sum_all array to pandas\n",
    "realtime_post_sum_summary = pd.DataFrame(data=realtime_posterior_sum_all,columns=('realtime_rip','rt_max_arm',\n",
    "                                                                                  'rt_two_messages','rt_delay'))\n",
    "realtime_post_sum_summary.shape\n",
    "# check numbering for ripples 4, 5, 6\n",
    "# also, looks like it never switch to an outer arm if the decode starts in the box\n",
    "# looks like many replays fail because it doesn't get 10 bins of data - this may be a result of empty bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "realtime rips (694, 7)\n",
      "offline rips (1256, 7)\n",
      "(553, 15)\n"
     ]
    }
   ],
   "source": [
    "# to match offline, add 1958987 to realtime timestamps\n",
    "# shift for realtime ripple detection delay: subtract 2100\n",
    "#45317550 45321300\n",
    "\n",
    "realtime_rips = stim_lockout3[stim_lockout3['lockout_state']==1]\n",
    "print('realtime rips',realtime_rips.shape)\n",
    "offline_rips = rips.reset_index()\n",
    "print('offline rips',offline_rips.shape)\n",
    "offline_rips['adj_timestamp'] = offline_rips['timestamp']\n",
    "realtime_rips['adj_timestamp'] = realtime_rips['timestamp']+1958987-2100\n",
    "realtime_rips\n",
    "# merge real-time and offline ripples \n",
    "# offline ripple start is 50-100 msec before real-time\n",
    "# try a tolerance of 100 msec = 3000 timestamps\n",
    "merged_ripple_times = pd.merge_asof(offline_rips,realtime_rips,on='adj_timestamp',tolerance=3000,direction='nearest')\n",
    "matching_offline_rips = merged_ripple_times[merged_ripple_times['lockout_num']>0]\n",
    "print(matching_offline_rips.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 13., 424.,  91.,  24.]),\n",
       " array([0, 1, 2, 3, 4]),\n",
       " <a list of 4 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# shows number of offline ripples that match two realtime ripples (duplicates)\n",
    "# look at value of 0 bin in histogram (23)\n",
    "plt.hist(matching_offline_rips['lockout_num'].diff().values,bins=np.arange(0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offline posteriors, 150 uV threshold\n",
    "#offline arm ends 8, 25, 42, 59, 77, 94, 111, 128, 145 \n",
    "arm_coords = [[0,8],[13,25],[30,42],[47,59],[65,77],[82,94],[99,111],[116,128],[133,145]]\n",
    "\n",
    "# now need to plot offline ripples that are mismatched\n",
    "\n",
    "posterior_offline = posteriors2.reset_index()\n",
    "offline_pos = binned_linear_pos.reset_index()\n",
    "merged_off_post_pos = pd.merge_asof(posterior_offline,offline_pos,on='timestamp',direction='nearest')\n",
    "offline_posterior_sum_all = np.zeros((len(matching_offline_rips),12))\n",
    "\n",
    "for index, rip_timestamp in enumerate(matching_offline_rips['timestamp_x']):\n",
    "    if matching_offline_rips['lockout_num'][index:index+1].values in non_matching['realtime_rip'].values:\n",
    "        print(matching_offline_rips['lockout_num'][index:index+1].values)\n",
    "        #print(rip_timestamp-30*300,rip_timestamp+30*300,index)\n",
    "\n",
    "        posterior_to_plot = merged_off_post_pos[(merged_off_post_pos['timestamp'] > rip_timestamp-30*300) & \n",
    "                                            (merged_off_post_pos['timestamp'] < rip_timestamp+30*300)]\n",
    "\n",
    "        realtime_ripple_num = matching_offline_rips['lockout_num'][index:index+1].values\n",
    "        ripple_num_index = int(len(posterior_to_plot)*0.55)\n",
    "        ripple_num = posterior_to_plot[ripple_num_index:ripple_num_index+1]['ripple_grp'].values\n",
    "    \n",
    "        # calculate posterior sum during ripple\n",
    "        # we need to only take out the time when ripple_grp matches ripple_grp at the middle of the plotting bin\n",
    "    \n",
    "        #post_sum_times = posterior_to_plot[posterior_to_plot['ripple_grp'] > 0]\n",
    "        post_sum_times = posterior_to_plot[posterior_to_plot['ripple_grp'] == ripple_num[0]]\n",
    "        ripple_length = post_sum_times.shape[0]\n",
    "        # sum each arm over whole ripple\n",
    "        post_sum_ripple = np.zeros((ripple_length,9))\n",
    "        for i in np.arange(0,ripple_length):\n",
    "            if i == 0:\n",
    "                for j in np.arange(0,len(arm_coords),1):\n",
    "                    post_sum_ripple[i,j] = post_sum_times.iloc[i,4:150].values[arm_coords[j][0]:arm_coords[j][1]].sum()\n",
    "\n",
    "            else:\n",
    "                for j in np.arange(0,len(arm_coords),1):\n",
    "                    post_sum_ripple[i,j] = post_sum_ripple[i-1,j] + post_sum_times.iloc[i,4:150].values[arm_coords[j][0]:arm_coords[j][1]].sum()\n",
    "            \n",
    "        # normalize sum of whole ripple - this is the final row\n",
    "        post_sum_ripple[i] = post_sum_ripple[i]/post_sum_ripple[i].sum()\n",
    "    \n",
    "        ripple_times = posterior_to_plot.index[posterior_to_plot['ripple_grp'] > 0].tolist()\n",
    "\n",
    "        posterior_offline1 = posterior_to_plot.drop(['day_x','epoch_x','timestamp','time_x','num_spikes','dec_bin',\n",
    "                                                 'ripple_grp','day_y','epoch_y','time_y','linpos_flat',\n",
    "                                                 'linvel_flat'], axis=1)\n",
    "\n",
    "        posterior_offline2 = posterior_offline1.fillna(0)\n",
    "        post_heatmap = posterior_offline2.transpose()\n",
    "        post_heatmap = post_heatmap.iloc[::-1]\n",
    "\n",
    "        posterior_sum = np.around(post_sum_ripple[-1:],decimals=1)\n",
    "        posterior_sum = posterior_sum[0]\n",
    "    \n",
    "        if len(np.argwhere(posterior_sum>=0.5)):\n",
    "            arm_max = np.argwhere(posterior_sum>=0.5)[0][0]\n",
    "        else:\n",
    "            arm_max = 99 \n",
    "\n",
    "        # fill in current row of posterior sum array - seems to work\n",
    "        offline_posterior_sum_all[index,0] = ripple_num\n",
    "        offline_posterior_sum_all[index,1] = realtime_ripple_num\n",
    "        offline_posterior_sum_all[index,2] = arm_max\n",
    "        offline_posterior_sum_all[index,3] = posterior_sum[0]\n",
    "        offline_posterior_sum_all[index,4] = posterior_sum[1]\n",
    "        offline_posterior_sum_all[index,5] = posterior_sum[2]\n",
    "        offline_posterior_sum_all[index,6] = posterior_sum[3]\n",
    "        offline_posterior_sum_all[index,7] = posterior_sum[4]\n",
    "        offline_posterior_sum_all[index,8] = posterior_sum[5]\n",
    "        offline_posterior_sum_all[index,9] = posterior_sum[6]\n",
    "        offline_posterior_sum_all[index,10] = posterior_sum[7]\n",
    "        offline_posterior_sum_all[index,11] = posterior_sum[8]\n",
    "                                     \n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.title(f'Off rip {ripple_num}. RT rip {realtime_ripple_num} Arm {arm_max} {posterior_sum}')\n",
    "        ax = (sns.heatmap(post_heatmap,vmin=0, vmax=0.7))\n",
    "        ax.hlines([145-10,145-27,145-44,145-61,145-79,145-96,145-113,145-130], lw=2, color='w',*ax.get_xlim())\n",
    "        ax.scatter(np.arange(0,posterior_to_plot.shape[0]),145-posterior_to_plot['linpos_flat'].values,s=2,alpha=1,color='cyan')\n",
    "        ax.vlines([ripple_times-posterior_to_plot.index[0]],lw=1,color='w',alpha=0.2,*ax.get_ylim())\n",
    "    \n",
    "        # final step: save the figure\n",
    "        #plt.savefig(f'/stelmo/mcoulter/posterior_plots_by_ripple/2-4-20/remy_20_2_offline_rip_nonmatching_{ripple_num}_real_rip_{realtime_ripple_num}_timestamp_{rip_timestamp}.jpg')\n",
    "\n",
    "# convert offline_posterior_sum_all array to pandas\n",
    "off_post_sum_summary = pd.DataFrame(data=offline_posterior_sum_all,columns=('offline_rip','realtime_rip',\n",
    "                                                                            'off_max_arm','box','arm1','arm2',\n",
    "                                                                            'arm3','arm4','arm5','arm6',\n",
    "                                                                            'arm7','arm8'))\n",
    "\n",
    "off_post_sum_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join offline and realtime replay summaries\n",
    "replay_summary_combined = pd.DataFrame.join(off_post_sum_summary,realtime_post_sum_summary,on='realtime_rip',\n",
    "                                            how='outer',lsuffix='off',rsuffix='rt')\n",
    "replay_combined_matching = replay_summary_combined[replay_summary_combined['offline_rip']>0]\n",
    "#replay_combined_matching = replay_combined_matching[replay_combined_matching['rt_two_messages']<1]\n",
    "#replay_summary_combined['realtime_ripoff'].values\n",
    "print(replay_combined_matching.shape)\n",
    "plt.hist(replay_combined_matching['realtime_rip'].diff(),bins=np.arange(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there a way to remove the duplicates? - should we?\n",
    "# include fractions in the print out summary\n",
    "\n",
    "# re-run without dealy\n",
    "# re-run with delay and full session\n",
    "\n",
    "# make histogram of classification for all replays\n",
    "\n",
    "#summarize matching between offline and realtime\n",
    "print('total matching:',replay_combined_matching.shape[0])\n",
    "\n",
    "#exact match\n",
    "print('exact match:',(replay_combined_matching[replay_combined_matching['off_max_arm'].values == replay_combined_matching['rt_max_arm'].values]).shape[0])\n",
    "\n",
    "# non-matching\n",
    "non_matching = replay_combined_matching[replay_combined_matching['off_max_arm'].values != replay_combined_matching['rt_max_arm'].values]\n",
    "print('non-matching:',non_matching.shape[0])\n",
    "# count for each arm in realtime replays\n",
    "print('realtime below 0.5:',non_matching[non_matching['rt_max_arm'] == 99].shape[0])\n",
    "print('realtime box:',non_matching[non_matching['rt_max_arm'] == 0].shape[0])\n",
    "print('realtime arm 1:',non_matching[non_matching['rt_max_arm'] == 1].shape[0])\n",
    "print('realtime arm 2:',non_matching[non_matching['rt_max_arm'] == 2].shape[0])\n",
    "print('realtime arm 3:',non_matching[non_matching['rt_max_arm'] == 3].shape[0])\n",
    "print('realtime arm 4:',non_matching[non_matching['rt_max_arm'] == 4].shape[0])\n",
    "print('realtime arm 5:',non_matching[non_matching['rt_max_arm'] == 5].shape[0])\n",
    "print('realtime arm 6:',non_matching[non_matching['rt_max_arm'] == 6].shape[0])\n",
    "print('realtime arm 7:',non_matching[non_matching['rt_max_arm'] == 7].shape[0])\n",
    "print('realtime arm 8:',non_matching[non_matching['rt_max_arm'] == 8].shape[0])\n",
    "\n",
    "# offline: no arm above 0.5\n",
    "print('offline < 0.5, mismatch total:',non_matching[non_matching['off_max_arm'] == 99].shape[0])\n",
    "print('offline < 0.5, realtime box:',non_matching[(non_matching['off_max_arm'] == 99) & (non_matching['rt_max_arm'] == 0)].shape[0])\n",
    "print('offline < 0.5, realtime other arm:',non_matching[(non_matching['off_max_arm'] == 99) & (non_matching['rt_max_arm'] != 0)].shape[0])\n",
    "\n",
    "# offline: box\n",
    "print('offline box, mismatch total:',non_matching[non_matching['off_max_arm'] == 0].shape[0])\n",
    "print('offline box, realtime < 0.5:',non_matching[(non_matching['off_max_arm'] == 0) & (non_matching['rt_max_arm'] == 99)].shape[0])\n",
    "print('offline box, realtime other arm:',non_matching[(non_matching['off_max_arm'] == 0) & (non_matching['rt_max_arm'] != 99)].shape[0])\n",
    "\n",
    "# offline: outer arm\n",
    "print('offline arm, mismatch total:',non_matching[(non_matching['off_max_arm'] > 0)&(non_matching['off_max_arm'] < 10)].shape[0])\n",
    "print('offline arm, realtime < 0.5:',non_matching[(non_matching['off_max_arm'] > 0)&(non_matching['off_max_arm'] < 10) & (non_matching['rt_max_arm'] == 99)].shape[0])\n",
    "print('offline arm, realtime box:',non_matching[(non_matching['off_max_arm'] > 0)&(non_matching['off_max_arm'] < 10) & (non_matching['rt_max_arm'] == 0)].shape[0])\n",
    "print('offline arm, realtime other arm:',non_matching[(non_matching['off_max_arm'] > 0)&(non_matching['off_max_arm'] < 10) & (non_matching['rt_max_arm'] > 0)&(non_matching['rt_max_arm'] < 10)].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate posterior error dataframe for real-time data\n",
    "post_error16 = decoder_data16.copy()\n",
    "\n",
    "post_error16.drop(columns=['rec_ind','bin_timestamp','wall_time','velocity','real_pos',\n",
    "                         'raw_x','raw_y','smooth_x','smooth_y','next_bin',\n",
    "                         'spike_count','ripple','ripple_number','ripple_length',\n",
    "                         'shortcut_message','box','arm1','arm2','arm3','arm4','arm5',\n",
    "                         'arm6','arm7','arm8'], inplace=True)\n",
    "post_error16.fillna(0,inplace=True)\n",
    "post_error16['max_position'] = post_error16.idxmax(axis=1)\n",
    "post_error16['max_position'] = post_error16['max_position'].str.replace('x','')\n",
    "post_error16['max_position'] = post_error16['max_position'].astype(int)\n",
    "\n",
    "#now need to add back columns 'timestamp','real_pos_time','real_pos'\n",
    "# try adding back spike_count too\n",
    "post_error16['timestamp'] = decoder_data16['bin_timestamp']\n",
    "post_error16['real_vel'] = decoder_data16['velocity']\n",
    "post_error16['real_pos'] = decoder_data16['real_pos']\n",
    "post_error16['spike_count'] = decoder_data16['spike_count']\n",
    "#this is the error column in centimeters\n",
    "post_error16['error_cm'] = abs(post_error16['max_position']-decoder_data16['real_pos'])*5\n",
    "\n",
    "post_error16\n",
    "post_error_plot16 = post_error16.copy()\n",
    "#post_error_plot9 = post_error_plot9\n",
    "post_error_plot16 = post_error_plot16[post_error_plot16['real_vel']>5]\n",
    "post_error_plot16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot decoded max posterior and real position\n",
    "plt.figure(figsize=(10,3))\n",
    "\n",
    "post_error_plot_subset = post_error_plot3[(post_error_plot3['timestamp']>124500000) & \n",
    "                                          (post_error_plot3['timestamp']<124700000)]\n",
    "\n",
    "plt.scatter(post_error_plot8['timestamp'].values,post_error_plot8['real_pos'].values,s=10)\n",
    "plt.scatter(post_error_plot8['timestamp'].values,post_error_plot8['max_position'].values,s=1,alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote error\n",
    "# only calculate error during movement\n",
    "#post_error_plot7 = post_error_plot7[post_error_plot7['real_vel']>8]\n",
    "post_error_plot5 = post_error_plot13.copy()\n",
    "\n",
    "#arm_coords_rt = [[0,7],[12,23],[28,39],[44,55],[60,71],[76,87],[92,103],[108,119],[124,135]]\n",
    "# new arm_coords 2-2020: [[0,8],[13,24],[29,40],[45,56],[61,72],[77,88],[93,104],[109,120],[125,136]]\n",
    "box = post_error_plot5[(post_error_plot5['real_pos']>=0) & (post_error_plot5['real_pos']<=8)]\n",
    "arm1 = post_error_plot5[(post_error_plot5['real_pos']>=13) & (post_error_plot5['real_pos']<=24)]\n",
    "arm2 = post_error_plot5[(post_error_plot5['real_pos']>=29) & (post_error_plot5['real_pos']<=40)]\n",
    "arm3 = post_error_plot5[(post_error_plot5['real_pos']>=45) & (post_error_plot5['real_pos']<=56)]\n",
    "arm4 = post_error_plot5[(post_error_plot5['real_pos']>=61) & (post_error_plot5['real_pos']<=72)]\n",
    "arm5 = post_error_plot5[(post_error_plot5['real_pos']>=77) & (post_error_plot5['real_pos']<=88)]\n",
    "arm6 = post_error_plot5[(post_error_plot5['real_pos']>=93) & (post_error_plot5['real_pos']<=104)]\n",
    "arm7 = post_error_plot5[(post_error_plot5['real_pos']>=109) & (post_error_plot5['real_pos']<=120)]\n",
    "arm8 = post_error_plot5[(post_error_plot5['real_pos']>=125) & (post_error_plot5['real_pos']<=136)]\n",
    "print(arm1.shape[0])\n",
    "print(post_error_plot5.shape)\n",
    "# fraction of bins with remote error\n",
    "box_remote_error = ((box.shape[0] - box[(box['max_position']>=0) & (box['max_position']<=8)].shape[0])/box.shape[0])\n",
    "arm1_remote_error = ((arm1.shape[0] - arm1[(arm1['max_position']>=13) & (arm1['max_position']<=24)].shape[0])/arm1.shape[0])\n",
    "arm2_remote_error = ((arm2.shape[0] - arm2[(arm2['max_position']>=29) & (arm2['max_position']<=40)].shape[0])/arm2.shape[0])\n",
    "arm3_remote_error = ((arm3.shape[0] - arm3[(arm3['max_position']>=45) & (arm3['max_position']<=56)].shape[0])/arm3.shape[0])\n",
    "arm4_remote_error = ((arm4.shape[0] - arm4[(arm4['max_position']>=61) & (arm4['max_position']<=72)].shape[0])/arm4.shape[0])\n",
    "arm5_remote_error = ((arm5.shape[0] - arm5[(arm5['max_position']>=77) & (arm5['max_position']<=88)].shape[0])/arm5.shape[0])\n",
    "arm6_remote_error = ((arm6.shape[0] - arm6[(arm6['max_position']>=93) & (arm6['max_position']<=104)].shape[0])/arm6.shape[0])\n",
    "arm7_remote_error = ((arm7.shape[0] - arm7[(arm7['max_position']>=109) & (arm7['max_position']<=120)].shape[0])/arm7.shape[0])\n",
    "arm8_remote_error = ((arm8.shape[0] - arm8[(arm8['max_position']>=125) & (arm8['max_position']<=136)].shape[0])/arm8.shape[0])\n",
    "\n",
    "#print error values\n",
    "print(box_remote_error,arm1_remote_error,arm2_remote_error,arm3_remote_error,arm4_remote_error,arm5_remote_error,arm6_remote_error,arm7_remote_error,arm8_remote_error)\n",
    "box_frac = box.shape[0]/post_error_plot5.shape[0]\n",
    "arm1_frac = arm1.shape[0]/post_error_plot5.shape[0]\n",
    "arm2_frac = arm2.shape[0]/post_error_plot5.shape[0]\n",
    "arm3_frac = arm3.shape[0]/post_error_plot5.shape[0]\n",
    "arm4_frac = arm4.shape[0]/post_error_plot5.shape[0]\n",
    "arm5_frac = arm5.shape[0]/post_error_plot5.shape[0]\n",
    "arm6_frac = arm6.shape[0]/post_error_plot5.shape[0]\n",
    "arm7_frac = arm7.shape[0]/post_error_plot5.shape[0]\n",
    "arm8_frac = arm8.shape[0]/post_error_plot5.shape[0]\n",
    "\n",
    "# fraction of arm-only time\n",
    "arm1_frac1 = arm1.shape[0]/(post_error_plot5.shape[0]*(1-box_frac))\n",
    "arm2_frac1 = arm2.shape[0]/(post_error_plot5.shape[0]*(1-box_frac))\n",
    "arm3_frac1 = arm3.shape[0]/(post_error_plot5.shape[0]*(1-box_frac))\n",
    "arm4_frac1 = arm4.shape[0]/(post_error_plot5.shape[0]*(1-box_frac))\n",
    "arm5_frac1 = arm5.shape[0]/(post_error_plot5.shape[0]*(1-box_frac))\n",
    "arm6_frac1 = arm6.shape[0]/(post_error_plot5.shape[0]*(1-box_frac))\n",
    "arm7_frac1 = arm7.shape[0]/(post_error_plot5.shape[0]*(1-box_frac))\n",
    "arm8_frac1 = arm8.shape[0]/(post_error_plot5.shape[0]*(1-box_frac))\n",
    "#weighted average for box + each arm\n",
    "print((box_remote_error*box_frac + arm1_remote_error*arm1_frac +arm2_remote_error*arm2_frac +\n",
    "       arm3_remote_error*arm3_frac +arm4_remote_error*arm4_frac +arm5_remote_error*arm5_frac +\n",
    "       arm6_remote_error*arm6_frac +arm7_remote_error*arm7_frac +arm8_remote_error*arm8_frac))\n",
    "# weighted average no box\n",
    "print((arm1_remote_error*arm1_frac1 +arm2_remote_error*arm2_frac1 +arm3_remote_error*arm3_frac1 +\n",
    "       arm4_remote_error*arm4_frac1 +arm5_remote_error*arm5_frac1 +arm6_remote_error*arm6_frac1 +\n",
    "       arm7_remote_error*arm7_frac1 +arm8_remote_error*arm8_frac1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local error\n",
    "# NOTE: need to update arm coords\n",
    "box_local = box[(box['max_position']>-1) & (box['max_position']<8)]\n",
    "arm1_local = arm1[(arm1['max_position']>11) & (arm1['max_position']<24)]\n",
    "arm2_local = arm2[(arm2['max_position']>27) & (arm2['max_position']<40)]\n",
    "arm3_local = arm3[(arm3['max_position']>43) & (arm3['max_position']<56)]\n",
    "arm4_local = arm4[(arm4['max_position']>59) & (arm4['max_position']<72)]\n",
    "arm5_local = arm5[(arm5['max_position']>75) & (arm5['max_position']<88)]\n",
    "arm6_local = arm6[(arm6['max_position']>91) & (arm6['max_position']<104)]\n",
    "arm7_local = arm7[(arm7['max_position']>107) & (arm7['max_position']<120)]\n",
    "arm8_local = arm8[(arm8['max_position']>123) & (arm8['max_position']<136)]\n",
    "\n",
    "box_local_error = np.median(box_local['error_cm'].values)\n",
    "arm1_local_error = np.median(arm1_local['error_cm'].values)\n",
    "arm2_local_error = np.median(arm2_local['error_cm'].values)\n",
    "arm3_local_error = np.median(arm3_local['error_cm'].values)\n",
    "arm4_local_error = np.median(arm4_local['error_cm'].values)\n",
    "arm5_local_error = np.median(arm5_local['error_cm'].values)\n",
    "arm6_local_error = np.median(arm6_local['error_cm'].values)\n",
    "arm7_local_error = np.median(arm7_local['error_cm'].values)\n",
    "arm8_local_error = np.median(arm8_local['error_cm'].values)\n",
    "\n",
    "print(arm1_local_error,arm2_local_error,arm3_local_error,arm4_local_error,arm5_local_error,arm6_local_error,arm7_local_error,arm8_local_error,)\n",
    "\n",
    "# total bins with local error\n",
    "local_total_bins = (arm1_local.shape[0]+arm2_local.shape[0]+arm3_local.shape[0]+arm4_local.shape[0]+\n",
    "                    arm5_local.shape[0]+arm6_local.shape[0]+arm7_local.shape[0]+arm8_local.shape[0])\n",
    "local_total_bins\n",
    "#weighted average for each arm\n",
    "(arm1_local_error*(arm1_local.shape[0]/local_total_bins)+arm2_local_error*(arm2_local.shape[0]/local_total_bins)+\n",
    " arm3_local_error*(arm3_local.shape[0]/local_total_bins)+arm4_local_error*(arm4_local.shape[0]/local_total_bins)+\n",
    " arm5_local_error*(arm5_local.shape[0]/local_total_bins)+arm6_local_error*(arm6_local.shape[0]/local_total_bins)+\n",
    " arm7_local_error*(arm7_local.shape[0]/local_total_bins)+\n",
    " arm8_local_error*(arm8_local.shape[0]/local_total_bins))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
