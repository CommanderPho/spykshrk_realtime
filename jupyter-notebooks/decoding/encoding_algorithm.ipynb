{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/daliu/Src/spykshrk_realtime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import json\n",
    "import os\n",
    "import scipy.signal\n",
    "import functools\n",
    "\n",
    "import math\n",
    "\n",
    "from spykshrk.realtime.simulator import nspike_data\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.util import gaussian, normal2D, apply_no_anim_boundary, simplify_pos_pandas\n",
    "from spykshrk.franklab.pp_decoder.pp_clusterless import OfflinePPDecoder\n",
    "from spykshrk.franklab.pp_decoder.data_containers import EncodeSettings, DecodeSettings, SpikeObservation, \\\n",
    "                                                         LinearPosition, StimLockout, Posteriors, \\\n",
    "                                                         FlatLinearPosition, SpikeWaves, SpikeFeatures, \\\n",
    "                                                         pos_col_format\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.visualization import DecodeVisualizer\n",
    "from spykshrk.franklab.pp_decoder.decode_error import LinearDecodeError\n",
    "from spykshrk.franklab.pp_decoder.util import normal_pdf_int_lookup\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "import pickle\n",
    "        \n",
    "%load_ext Cython\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#pd.set_option('float_format', '{:,.2f}'.format)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "#pd.set_option('display.width', 80)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "except:\n",
    "    print(\"No cluster or client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=15)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load merged rec HDF store based on config\n",
    "\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/ripple_dec/bond.config.json'\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/dec_60uv/bond.config.json'\n",
    "config_file = '/home/daliu/Src/spykshrk_realtime/config/bond_single.json'\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "day = config['simulator']['nspike_animal_info']['days'][0]\n",
    "epoch = config['simulator']['nspike_animal_info']['epochs'][0]\n",
    "time_bin_size = config['pp_decoder']['bin_size']\n",
    "\n",
    "# Extract just encode and decode settings from config\n",
    "encode_settings = EncodeSettings(config)\n",
    "decode_settings = DecodeSettings(config)\n",
    "\n",
    "# Grab animal linearized real position\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n",
    "\n",
    "spk = nspike_data.SpkDataStream(nspike_anim)\n",
    "spk_data = SpikeWaves(spk.data)\n",
    "\n",
    "# Encapsulate linear position\n",
    "lin_obj = LinearPosition.from_nspike_posmat(pos_data, encode_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "spk_amp = spk_data.max(axis=1)\n",
    "spk_amp = spk_amp.to_frame().pivot_table(index=['day','epoch','elec_grp_id','timestamp','time'], \n",
    "                                         columns='channel', values=0)\n",
    "spk_amp= SpikeFeatures(spk_amp)\n",
    "spk_amp_thresh = spk_amp.get_above_threshold(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def compute_observ_tet(dec_spk, enc_spk, tet_lin_pos, encode_settings):\n",
    "    \n",
    "    pos_distrib_tet = sp.stats.norm.pdf(np.expand_dims(encode_settings.pos_bins, 0),\n",
    "                                        np.expand_dims(tet_lin_pos['linpos_flat'],1), \n",
    "                                        encode_settings.pos_kernel_std)\n",
    "\n",
    "    mark_contrib = normal_pdf_int_lookup(np.expand_dims(dec_spk, 1), \n",
    "                                         np.expand_dims(enc_spk,0), \n",
    "                                         encode_settings.mark_kernel_std)\n",
    "\n",
    "    all_contrib = np.prod(mark_contrib, axis=2)\n",
    "\n",
    "    observ = np.matmul(all_contrib, pos_distrib_tet)\n",
    "    \n",
    "    ret_df = pd.DataFrame(observ, index=dec_spk.index, \n",
    "                          columns=[pos_col_format(pos_ii, observ.shape[1]) \n",
    "                                   for pos_ii in range(observ.shape[1])])\n",
    "    return ret_df\n",
    "\n",
    "\n",
    "grp = spk_amp_thresh.groupby('elec_grp_id')\n",
    "observations = {}\n",
    "task = []\n",
    "chunksize = 2000\n",
    "for tet_id, spk_tet in grp:\n",
    "    tet_lin_pos = (lin_obj.get_irregular_resampled(spk_tet.index.get_level_values('timestamp'))\n",
    "                   .get_mapped_single_axis())\n",
    "    dask_spk_tet = dd.from_pandas(spk_tet.get_simple_index(), chunksize=chunksize)\n",
    "    \n",
    "    df_meta = pd.DataFrame([], columns=[pos_col_format(ii, encode_settings.pos_num_bins) \n",
    "                                        for ii in range(encode_settings.pos_num_bins)])\n",
    "    \n",
    "    task.append(dask_spk_tet.map_partitions(functools.partial(compute_observ_tet, enc_spk=spk_tet,\n",
    "                                                              tet_lin_pos=tet_lin_pos,\n",
    "                                                              encode_settings=encode_settings), \n",
    "                                            meta=df_meta))\n",
    "    \n",
    "results = dask.compute(*task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tet_ids = np.unique(spk_amp.index.get_level_values('elec_grp_id'))\n",
    "observ_tet_list = []\n",
    "grp = spk_amp_thresh.groupby('elec_grp_id')\n",
    "for tet_ii, (tet_id, grp_spk) in enumerate(grp):\n",
    "    tet_result = results[tet_ii]\n",
    "    tet_result.set_index(grp_spk.index, inplace=True)\n",
    "    observ_tet_list.append(tet_result)\n",
    "\n",
    "observ = pd.concat(observ_tet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "observ_obj = SpikeObservation.from_df(observ.sort_index(level=['day', 'epoch', \n",
    "                                                               'timestamp', 'elec_grp_id']), )"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}