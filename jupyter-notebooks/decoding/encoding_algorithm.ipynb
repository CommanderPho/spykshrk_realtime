{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/daliu/Src/spykshrk_realtime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import json\n",
    "import os\n",
    "import scipy.signal\n",
    "import functools\n",
    "\n",
    "import math\n",
    "\n",
    "from spykshrk.realtime.simulator import nspike_data\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.util import gaussian, normal2D, apply_no_anim_boundary, simplify_pos_pandas\n",
    "from spykshrk.franklab.pp_decoder.pp_clusterless import OfflinePPDecoder\n",
    "from spykshrk.franklab.pp_decoder.data_containers import EncodeSettings, DecodeSettings, SpikeObservation, \\\n",
    "                                                         LinearPosition, StimLockout, Posteriors, \\\n",
    "                                                         FlatLinearPosition, SpikeWaves, SpikeFeatures, \\\n",
    "                                                         pos_col_format\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.visualization import DecodeVisualizer\n",
    "from spykshrk.franklab.pp_decoder.decode_error import LinearDecodeError\n",
    "from spykshrk.franklab.pp_decoder.util import normal_pdf_int_lookup\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "import pickle\n",
    "        \n",
    "%load_ext Cython\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#pd.set_option('float_format', '{:,.2f}'.format)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "#pd.set_option('display.width', 80)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "except:\n",
    "    print(\"No cluster or client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=15)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load merged rec HDF store based on config\n",
    "\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/ripple_dec/bond.config.json'\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/dec_60uv/bond.config.json'\n",
    "config_file = '/home/daliu/Src/spykshrk_realtime/config/bond_single.json'\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "day = config['simulator']['nspike_animal_info']['days'][0]\n",
    "epoch = config['simulator']['nspike_animal_info']['epochs'][0]\n",
    "time_bin_size = config['pp_decoder']['bin_size']\n",
    "\n",
    "# Extract just encode and decode settings from config\n",
    "encode_settings = EncodeSettings(config)\n",
    "decode_settings = DecodeSettings(config)\n",
    "\n",
    "# Grab animal linearized real position\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n",
    "\n",
    "spk = nspike_data.SpkDataStream(nspike_anim)\n",
    "spk_data = SpikeWaves(spk.data)\n",
    "\n",
    "# Encapsulate linear position\n",
    "lin_obj = LinearPosition.from_nspike_posmat(pos_data, encode_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "spk_amp = spk_data.max(axis=1)\n",
    "spk_amp = spk_amp.to_frame().pivot_table(index=['day','epoch','electrode_group_id','timestamp','time'], \n",
    "                                         columns='channel', values=0)\n",
    "spk_amp= SpikeFeatures(spk_amp)\n",
    "spk_amp_thresh = spk_amp.get_above_threshold(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "def compute_observ_tet(tet_id, chunk_ii, lin_obj, dec_spk_data,\n",
    "                       enc_spk_index, enc_spk_data, encode_settings):\n",
    "    \n",
    "    print(\"Computing {}: {}\".format(tet_id, chunk_ii))\n",
    "    tet_lin_pos = (lin_obj.get_irregular_resampled(enc_spk_index.get_level_values('timestamp'))\n",
    "                   .get_mapped_single_axis())\n",
    "    pos_distrib_tet = sp.stats.norm.pdf(np.expand_dims(encode_settings.pos_bins, 0),\n",
    "                                        np.expand_dims(tet_lin_pos['linpos_flat'],1), \n",
    "                                        encode_settings.pos_kernel_std)\n",
    "\n",
    "    mark_contrib = normal_pdf_int_lookup(np.expand_dims(dec_spk_data, 1), \n",
    "                                         np.expand_dims(enc_spk_data,0), \n",
    "                                         encode_settings.mark_kernel_std)\n",
    "\n",
    "    all_contrib = np.prod(mark_contrib, axis=2)\n",
    "\n",
    "    print(\"Done {}\".format(tet_id))\n",
    "\n",
    "    return np.matmul(all_contrib, pos_distrib_tet)  \n",
    "\n",
    "\n",
    "grp = spk_amp_thresh.groupby('tet')\n",
    "observations = {}\n",
    "task = []\n",
    "chunking = 1000\n",
    "for tet_id, spk_tet in grp:\n",
    "    for chunk_ii in range(int(math.ceil(len(spk_tet)/chunking))):\n",
    "        if (chunk_ii + 1) * chunking > len(spk_tet):\n",
    "            chunk_start = chunk_ii * chunking\n",
    "            chunk_end = len(spk_tet)\n",
    "        else:\n",
    "            chunk_start = chunk_ii * chunking\n",
    "            chunk_end = (chunk_ii + 1) * chunking\n",
    "            \n",
    "        task.append(dask.delayed(compute_observ_tet)\n",
    "                    (tet_id, chunk_ii, lin_obj, \n",
    "                     spk_tet.values[chunk_start:chunk_end, :],\n",
    "                     spk_tet.index, spk_tet.values,\n",
    "                     encode_settings))\n",
    "            \n",
    "    #compute_observ_tet(lin_obj, spk_tet.index, spk_tet.values, encode_settings)\n",
    "    #task.append(dask.delayed(compute_observ_tet)(tet_id, lin_obj, spk_tet.index, spk_tet.values, encode_settings))\n",
    "    \n",
    "observ_results = dask.compute(*task)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"    print(\"Starting tet {}\".format(tet_id))\n",
    "    tet_lin_pos = (lin_obj.get_irregular_resampled(spk_tet.index.get_level_values('timestamp'))\n",
    "                   .get_mapped_single_axis())\n",
    "    pos_distrib_tet = sp.stats.norm.pdf(np.expand_dims(encode_settings.pos_bins, 0),\n",
    "                                        np.expand_dims(tet_lin_pos['linpos_flat'],1), \n",
    "                                        encode_settings.pos_kernel_std)\n",
    "    marks_tet = spk_tet.values\n",
    "    \n",
    "    mark_contrib = normal_pdf_int_lookup(np.expand_dims(marks_tet, 0), \n",
    "                                         np.expand_dims(marks_tet,1), \n",
    "                                         encode_settings.mark_kernel_std)\n",
    "    \n",
    "    all_contrib = np.prod(mark_contrib, axis=2)\n",
    "    \n",
    "    observations[tet_id] = pd.DataFrame(data=np.matmul(all_contrib, pos_distrib_tet), index=spk_tet.index,\n",
    "                                        columns=[pos_col_format(x_bin, encode_settings.pos_num_bins) \n",
    "                                                 for x_bin in range(encode_settings.pos_num_bins)])\n",
    "\"\"\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def compute_observ_tet(dec_spk, enc_spk, tet_lin_pos, encode_settings):\n",
    "    \n",
    "    pos_distrib_tet = sp.stats.norm.pdf(np.expand_dims(encode_settings.pos_bins, 0),\n",
    "                                        np.expand_dims(tet_lin_pos['linpos_flat'],1), \n",
    "                                        encode_settings.pos_kernel_std)\n",
    "\n",
    "    mark_contrib = normal_pdf_int_lookup(np.expand_dims(dec_spk, 1), \n",
    "                                         np.expand_dims(enc_spk,0), \n",
    "                                         encode_settings.mark_kernel_std)\n",
    "\n",
    "    all_contrib = np.prod(mark_contrib, axis=2)\n",
    "\n",
    "    observ = np.matmul(all_contrib, pos_distrib_tet)\n",
    "    \n",
    "    return pd.DataFrame(observ, index=dec_spk.index, \n",
    "                        columns=[pos_col_format(pos_ii, observ.shape[1]) \n",
    "                                 for pos_ii in range(observ.shape[1])])\n",
    "\n",
    "\n",
    "grp = spk_amp_thresh.groupby('electrode_group_id')\n",
    "observations = {}\n",
    "task = []\n",
    "chunksize = 2000\n",
    "for tet_id, spk_tet in grp:\n",
    "    tet_lin_pos = (lin_obj.get_irregular_resampled(spk_tet.index.get_level_values('timestamp'))\n",
    "                   .get_mapped_single_axis())\n",
    "    dask_spk_tet = dd.from_pandas(spk_tet.get_simple_index(), chunksize=chunksize)\n",
    "    \n",
    "    \n",
    "    task.append(dask_spk_tet.map_partitions(functools.partial(compute_observ_tet, enc_spk=spk_tet,\n",
    "                                                              tet_lin_pos=tet_lin_pos,\n",
    "                                                              encode_settings=encode_settings), \n",
    "                                            meta=pd.DataFrame([], columns=range(450))))\n",
    "    \n",
    "results = dask.compute(*task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tet_ids = np.unique(spk_amp.index.get_level_values('tet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observ_tet_list = []\n",
    "grp = spk_amp_thresh.groupby('tet')\n",
    "for tet_ii, (tet_id, grp_spk) in enumerate(grp):\n",
    "    tet_result = results[tet_ii]\n",
    "    tet_result.set_index(grp_spk.index, inplace=True)\n",
    "    observ_tet_list.append(tet_result)\n",
    "\n",
    "observ = pd.concat(observ_tet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observ.sort_index(level=['day', 'epoch', 'timestamp', 'tet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].iloc[120:125].T.plot(figsize=[15,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%prun -r -s cumulative\n",
    "grp = spk_amp_thresh.groupby('tet')\n",
    "observations = {}\n",
    "for tet_id, spk_tet in grp:\n",
    "    print(\"Starting tet {}\".format(tet_id))\n",
    "    tet_lin_pos = (lin_obj.get_irregular_resampled(spk_tet.index.get_level_values('timestamp'))\n",
    "                   .get_mapped_single_axis())\n",
    "    pos_distrib_tet = sp.stats.norm.pdf(np.expand_dims(encode_settings.pos_bins, 0),\n",
    "                                        np.expand_dims(tet_lin_pos['linpos_flat'],1), \n",
    "                                        encode_settings.pos_kernel_std)\n",
    "    marks_tet = spk_tet.values\n",
    "    \n",
    "    encoding_model = sp.stats.norm(loc=marks_tet,\n",
    "                                      scale=encode_settings.mark_kernel_std)\n",
    "                                      #x=np.expand_dims(marks_tet, 0)))\n",
    "    \n",
    "    #observations[tet_id] = np.matmul(np.squeeze(np.prod(mark_contrib, axis=2)), pos_distrib_test)\n",
    "                    \n",
    "    observations[tet_id] = np.zeros([marks_tet.shape[0], len(encode_settings.pos_bins)])\n",
    "    \n",
    "    for dec_spk_ii, dec_mark in enumerate(marks_tet):\n",
    "        mark_contrib = np.prod(encoding_model.pdf(dec_mark), \n",
    "                               axis=1)\n",
    "        observations[tet_id][dec_spk_ii, :] = np.matmul(mark_contrib, pos_distrib_tet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}