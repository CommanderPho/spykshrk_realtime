{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/daliu/Src/spykshrk_realtime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import json\n",
    "import os\n",
    "import scipy.signal\n",
    "import functools\n",
    "import holoviews as hv\n",
    "\n",
    "import math\n",
    "\n",
    "from spykshrk.realtime.simulator import nspike_data\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.util import gaussian, normal2D, apply_no_anim_boundary, simplify_pos_pandas\n",
    "from spykshrk.franklab.pp_decoder.pp_clusterless import OfflinePPDecoder\n",
    "from spykshrk.franklab.pp_decoder.data_containers import EncodeSettings, DecodeSettings, SpikeObservation, \\\n",
    "                                                         LinearPosition, StimLockout, Posteriors, \\\n",
    "                                                         FlatLinearPosition, SpikeWaves, SpikeFeatures, \\\n",
    "                                                         pos_col_format\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.visualization import DecodeVisualizer\n",
    "from spykshrk.franklab.pp_decoder.decode_error import LinearDecodeError\n",
    "from spykshrk.franklab.pp_decoder.util import normal_pdf_int_lookup\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "import cloudpickle\n",
    "        \n",
    "%load_ext Cython\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "hv.extension('matplotlib')\n",
    "hv.extension('bokeh')\n",
    "#pd.set_option('float_format', '{:,.2f}'.format)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "#pd.set_option('display.width', 80)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "except:\n",
    "    print(\"No cluster or client\")\n",
    "    \n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=15)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load merged rec HDF store based on config\n",
    "\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/ripple_dec/bond.config.json'\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/dec_60uv/bond.config.json'\n",
    "config_file = '/home/daliu/Src/spykshrk_realtime/config/bond_single.json'\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "day = config['simulator']['nspike_animal_info']['days'][0]\n",
    "epoch = config['simulator']['nspike_animal_info']['epochs'][0]\n",
    "time_bin_size = config['pp_decoder']['bin_size']\n",
    "\n",
    "# Extract just encode and decode settings from config\n",
    "encode_settings = EncodeSettings(config)\n",
    "decode_settings = DecodeSettings(config)\n",
    "\n",
    "# Grab animal linearized real position\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n",
    "\n",
    "spk = nspike_data.SpkDataStream(nspike_anim)\n",
    "spk_data = SpikeWaves.from_df(spk.data, encode_settings)\n",
    "\n",
    "# Encapsulate linear position\n",
    "lin_obj = LinearPosition.from_nspike_posmat(pos_data, encode_settings)\n",
    "linflat_obj = lin_obj.get_mapped_single_axis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_settings.pos_kernel_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spk_amp = spk_data.max(axis=1)\n",
    "spk_amp = spk_amp.to_frame().pivot_table(index=['day','epoch','elec_grp','timestamp','time'], \n",
    "                                         columns='channel', values=0)\n",
    "spk_amp= SpikeFeatures(spk_amp)\n",
    "spk_amp_thresh = spk_amp.get_above_threshold(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cloudpickle.dumps(spk_amp_thresh.copy())\n",
    "loaded = cloudpickle.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_amp_thresh.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def compute_observ_tet(dec_spk, enc_spk, tet_lin_pos, occupancy, encode_settings):\n",
    "\n",
    "    pos_distrib_tet = sp.stats.norm.pdf(np.expand_dims(encode_settings.pos_bins, 0),\n",
    "                                        np.expand_dims(tet_lin_pos['linpos_flat'],1), \n",
    "                                        encode_settings.pos_kernel_std)\n",
    "\n",
    "    mark_contrib = normal_pdf_int_lookup(np.expand_dims(dec_spk, 1), \n",
    "                                         np.expand_dims(enc_spk,0), \n",
    "                                         encode_settings.mark_kernel_std)\n",
    "\n",
    "    all_contrib = np.prod(mark_contrib, axis=2)\n",
    "\n",
    "    del mark_contrib\n",
    "    \n",
    "    observ = np.matmul(all_contrib, pos_distrib_tet)\n",
    "    \n",
    "    del all_contrib\n",
    "    \n",
    "    # occupancy normalize\n",
    "    observ = observ / (occupancy + 1e-10)\n",
    "    \n",
    "    # normalize each row\n",
    "    observ = observ / observ.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    ret_df = pd.DataFrame(observ, index=dec_spk.index, \n",
    "                          columns=[pos_col_format(pos_ii, observ.shape[1]) \n",
    "                                   for pos_ii in range(observ.shape[1])])\n",
    "    return ret_df\n",
    "\n",
    "occ, _ = np.histogram(a=linflat_obj['linpos_flat'], bins=encode_settings.pos_bin_edges,normed=True)\n",
    "occ = np.convolve(occ, encode_settings.pos_kernel)[int(len(occ)/2):int(len(occ)*3/2)]\n",
    "\n",
    "grp = spk_amp_thresh.groupby('elec_grp')\n",
    "observations = {}\n",
    "task = []\n",
    "chunksize = 2000\n",
    "for tet_id, spk_tet in grp:\n",
    "    spk_tet.index = spk_tet.index.droplevel('elec_grp')\n",
    "    tet_lin_pos = (lin_obj.get_irregular_resampled(spk_tet.index.get_level_values('timestamp'))\n",
    "                   .get_mapped_single_axis())\n",
    "    \n",
    "    # Velocity threshold on spikes and position\n",
    "    #tet_lin_pos_thresh = tet_lin_pos.get_above_velocity(10.)\n",
    "    #spk_tet_thresh = spk_tet.reindex(tet_lin_pos_thresh.index)\n",
    "    tet_lin_pos_thresh = tet_lin_pos.copy()\n",
    "    spk_tet_thresh = spk_tet.copy()\n",
    "    # Decode from all spikes\n",
    "    dask_spk_tet = dd.from_pandas(spk_tet.get_simple_index().copy(), chunksize=chunksize)\n",
    "    \n",
    "    df_meta = pd.DataFrame([], columns=[pos_col_format(ii, encode_settings.pos_num_bins) \n",
    "                                        for ii in range(encode_settings.pos_num_bins)])\n",
    "    \n",
    "    # Setup decode of all spikes from encoding of velocity threshold spikes\n",
    "    task.append(dask_spk_tet.map_partitions(functools.partial(compute_observ_tet, enc_spk=spk_tet_thresh,\n",
    "                                                              tet_lin_pos=tet_lin_pos_thresh, occupancy=occ,\n",
    "                                                              encode_settings=encode_settings), \n",
    "                                            meta=df_meta))\n",
    "    \n",
    "results = dask.compute(*task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tet_ids = np.unique(spk_amp.index.get_level_values('elec_grp'))\n",
    "observ_tet_list = []\n",
    "grp = spk_amp_thresh.groupby('elec_grp')\n",
    "for tet_ii, (tet_id, grp_spk) in enumerate(grp):\n",
    "    tet_result = results[tet_ii]\n",
    "    tet_result.set_index(grp_spk.index, inplace=True)\n",
    "    observ_tet_list.append(tet_result)\n",
    "\n",
    "observ = pd.concat(observ_tet_list)\n",
    "observ_obj = SpikeObservation.from_df(observ.sort_index(level=['day', 'epoch', \n",
    "                                                               'timestamp', 'elec_grp']), )\n",
    "\n",
    "observ_obj['elec_grp'] = observ_obj.index.get_level_values('elec_grp')\n",
    "observ_obj.index = observ_obj.index.droplevel('elec_grp')\n",
    "\n",
    "observ_obj['position'] = (lin_obj.get_irregular_resampled(observ_obj.index.get_level_values('timestamp')).\n",
    "                          get_mapped_single_axis()['linpos_flat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run PP decoding algorithm\n",
    "time_bin_size = 30\n",
    "\n",
    "decoder = OfflinePPDecoder(lin_obj=lin_obj, observ_obj=observ_obj,\n",
    "                           encode_settings=encode_settings, decode_settings=decode_settings, \n",
    "                           which_trans_mat='learned', time_bin_size=time_bin_size)\n",
    "\n",
    "posteriors = decoder.run_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "observ_obj['dec_bin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output backend='matplotlib' size=300\n",
    "%%opts Points (s=200 marker='^' )\n",
    "%%opts Curve [aspect=3]\n",
    "%%opts Text (text_align='left')\n",
    "\n",
    "sel_distrib = observ_obj.loc[:, pos_col_format(0,encode_settings.pos_num_bins):         \n",
    "                             pos_col_format(encode_settings.pos_num_bins-1,\n",
    "                                            encode_settings.pos_num_bins)]\n",
    "    \n",
    "sel_pos = observ_obj.loc[:, 'position']\n",
    "\n",
    "max_prob = sel_distrib.max().max()/2\n",
    "\n",
    "def plot_observ(big_bin, small_bin):\n",
    "    bin_id = small_bin + 10000 * big_bin\n",
    "    spks_in_bin = sel_distrib.loc[observ_obj['dec_bin'] == bin_id, :]\n",
    "    pos_in_bin = sel_pos.loc[observ_obj['dec_bin'] == bin_id, :]\n",
    "    \n",
    "    num_spks = len(spks_in_bin)\n",
    "    plot_list = []\n",
    "    if num_spks == 0:\n",
    "        plot_list.append(hv.Curve((0,[max_prob-0.01]), \n",
    "                                   extents=(0, 0, encode_settings.pos_bins[-1], max_prob)))\n",
    "    for spk_observ, pos_observ in zip(spks_in_bin.values, pos_in_bin.values):\n",
    "        plot_list.append(hv.Curve(spk_observ, \n",
    "                                  extents=(0, 0, encode_settings.pos_bins[-1], max_prob)))\n",
    "\n",
    "        plot_list.append(hv.Points((pos_observ, [max_prob-0.01])))\n",
    "    return hv.Overlay(plot_list) * hv.Text(50,max_prob-0.05, \"num_spks: {num_spks}\\n\"\n",
    "                                           \"Timestamp: {timestamp}\\nTime: {time}\".\n",
    "                                           format(num_spks=num_spks, timestamp=time_bin_size*bin_id,\n",
    "                                                  time=time_bin_size*bin_id/30000))\n",
    "\n",
    "#Ind = Stream.define('stuff', ind=0)\n",
    "\n",
    "dmap = hv.DynamicMap(plot_observ, kdims=['big_bin', 'small_bin'], label=\"test\")\n",
    "#dmap = hv.DynamicMap(plot_observ, kdims=\n",
    "#                     [hv.Dimension('bin_id', range=(0, observ_obj['dec_bin'].iloc[-1]), step=1)])\n",
    "#dmap = hv.DynamicMap(plot_observ, kdims=\n",
    "#                     [hv.Dimension('bin_id', values=observ_obj['dec_bin'].unique())])\n",
    "\n",
    "#dmap.redim.values(bin_id=range(0, observ_obj['dec_bin'].iloc[-1]))\n",
    "dmap.redim.range(small_bin=(0, 1000), big_bin=(0, observ_obj['dec_bin'].iloc[-1]/1000 + 1))\n",
    "#dmap.redim.range(bin_id=(0, observ_obj['dec_bin'].iloc[-1]))\n",
    "#dmap.redim.values(bin_id=[4,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot posteriors\n",
    "#plt_ranges = [[2461, 2641]]\n",
    "plt_ranges = [[2461, 3405]]\n",
    "#plt_ranges = [[2930, 3000]]\n",
    "#plt_ranges = [[3295, 3325]]\n",
    "    \n",
    "dec_viz = DecodeVisualizer(posteriors.get_relative_index(), linpos=lin_obj.get_relative_index(),\n",
    "                           enc_settings=encode_settings)\n",
    "for plt_range in plt_ranges:\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=[200,10])\n",
    "    dec_viz.plot_decode_image(plt_range=None, x_tick=10)\n",
    "    print(ax)\n",
    "    dec_viz.plot_linear_pos(lin_obj, plt_range)\n",
    "    #DecodeVisualizer.plot_stim_lockout(ax, stim_lockout, plt_range, encode_settings.arm_coordinates[2][1] + 10)\n",
    "    \n",
    "    #plt.xlim(plt_range)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}