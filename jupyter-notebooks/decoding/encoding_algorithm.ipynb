{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/daliu/Src/spykshrk_realtime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import json\n",
    "import os\n",
    "import scipy.signal\n",
    "import functools\n",
    "import holoviews as hv\n",
    "\n",
    "import math\n",
    "\n",
    "from spykshrk.util import AttrDict\n",
    "import spykshrk.franklab.filterframework_util as ff_util\n",
    "\n",
    "from spykshrk.realtime.simulator import nspike_data\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.util import gaussian, normal2D, apply_no_anim_boundary, simplify_pos_pandas, \\\n",
    "                                                normal_pdf_int_lookup\n",
    "from spykshrk.franklab.pp_decoder.pp_clusterless import OfflinePPDecoder, OfflinePPEncoder\n",
    "from spykshrk.franklab.pp_decoder.data_containers import EncodeSettings, DecodeSettings, SpikeObservation, \\\n",
    "                                                         LinearPosition, StimLockout, Posteriors, \\\n",
    "                                                         FlatLinearPosition, SpikeWaves, SpikeFeatures, \\\n",
    "                                                         pos_col_format, DayEpochTimeSeries\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.visualization import DecodeVisualizer\n",
    "from spykshrk.franklab.pp_decoder.decode_error import LinearDecodeError\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "import cloudpickle\n",
    "        \n",
    "%load_ext Cython\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "hv.extension('matplotlib')\n",
    "hv.extension('bokeh')\n",
    "#pd.set_option('float_format', '{:,.2f}'.format)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "#pd.set_option('display.width', 80)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "except:\n",
    "    print(\"No cluster or client\")\n",
    "    \n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=20, threads_per_worker=2)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load merged rec HDF store based on config\n",
    "\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/ripple_dec/bond.config.json'\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/dec_60uv/bond.config.json'\n",
    "config_file = '/home/daliu/Src/spykshrk_realtime/config/bond_single.json'\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "day = config['simulator']['nspike_animal_info']['days'][0]\n",
    "epoch = config['simulator']['nspike_animal_info']['epochs'][0]\n",
    "time_bin_size = config['pp_decoder']['bin_size']\n",
    "\n",
    "# Extract just encode and decode settings from config\n",
    "encode_settings = EncodeSettings(config)\n",
    "decode_settings = DecodeSettings(config)\n",
    "\n",
    "# Grab animal linearized real position\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n",
    "\n",
    "spk = nspike_data.SpkDataStream(nspike_anim)\n",
    "spk_data = SpikeWaves.from_df(spk.data, encode_settings)\n",
    "\n",
    "# Encapsulate linear position\n",
    "lin_obj = LinearPosition.from_nspike_posmat(pos_data, encode_settings)\n",
    "linflat_obj = lin_obj.get_mapped_single_axis()\n",
    "\n",
    "ripcons = nspike_data.RipplesConsData(nspike_anim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(ripcons.data_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spk_amp = spk_data.max(axis=1)\n",
    "spk_amp = spk_amp.to_frame().pivot_table(index=['day','epoch','elec_grp_id','timestamp','time'], \n",
    "                                         columns='channel', values=0)\n",
    "spk_amp= SpikeFeatures(spk_amp)\n",
    "spk_amp_thresh = spk_amp.get_above_threshold(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -r -s cumulative\n",
    "\n",
    "encoder = OfflinePPEncoder(linflat=linflat_obj, spk_amp=spk_amp_thresh, speed_thresh=0,\n",
    "                           encode_settings=encode_settings)\n",
    "results = encoder.run_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode_prof = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "tet_ids = np.unique(spk_amp.index.get_level_values('elec_grp_id'))\n",
    "observ_tet_list = []\n",
    "grp = spk_amp_thresh.groupby('elec_grp_id')\n",
    "for tet_ii, (tet_id, grp_spk) in enumerate(grp):\n",
    "    tet_result = results[tet_ii]\n",
    "    tet_result.set_index(grp_spk.index, inplace=True)\n",
    "    observ_tet_list.append(tet_result)\n",
    "\n",
    "observ = pd.concat(observ_tet_list)\n",
    "observ_obj = SpikeObservation.create_default(observ.sort_index(level=['day', 'epoch', \n",
    "                                                                      'timestamp', 'elec_grp_id']), \n",
    "                                             encode_settings.sampling_rate )\n",
    "\n",
    "observ_obj['elec_grp_id'] = observ_obj.index.get_level_values('elec_grp_id')\n",
    "observ_obj.index = observ_obj.index.droplevel('elec_grp_id')\n",
    "\n",
    "observ_obj['position'] = (lin_obj.get_irregular_resampled(observ_obj.index.get_level_values('timestamp')).\n",
    "                          get_mapped_single_axis()['linpos_flat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run PP decoding algorithm\n",
    "time_bin_size = 30\n",
    "\n",
    "decoder = OfflinePPDecoder(lin_obj=lin_obj, observ_obj=observ_obj,\n",
    "                           encode_settings=encode_settings, decode_settings=decode_settings, \n",
    "                           which_trans_mat='learned', time_bin_size=time_bin_size)\n",
    "\n",
    "posteriors = decoder.run_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output backend='matplotlib' size=300\n",
    "%%opts Points (s=200 marker='^' )\n",
    "%%opts Curve [aspect=3]\n",
    "%%opts Text (text_align='left')\n",
    "\n",
    "sel_distrib = observ_obj.loc[:, pos_col_format(0,encode_settings.pos_num_bins):         \n",
    "                             pos_col_format(encode_settings.pos_num_bins-1,\n",
    "                                            encode_settings.pos_num_bins)]\n",
    "    \n",
    "sel_pos = observ_obj.loc[:, 'position']\n",
    "\n",
    "max_prob = sel_distrib.max().max()/2\n",
    "\n",
    "def plot_observ(big_bin, small_bin):\n",
    "    bin_id = small_bin + 10000 * big_bin\n",
    "    spks_in_bin = sel_distrib.loc[observ_obj['dec_bin'] == bin_id, :]\n",
    "    pos_in_bin = sel_pos.loc[observ_obj['dec_bin'] == bin_id, :]\n",
    "    \n",
    "    num_spks = len(spks_in_bin)\n",
    "    plot_list = []\n",
    "    if num_spks == 0:\n",
    "        plot_list.append(hv.Curve((0,[max_prob-0.01]), \n",
    "                                   extents=(0, 0, encode_settings.pos_bins[-1], max_prob)))\n",
    "    for spk_observ, pos_observ in zip(spks_in_bin.values, pos_in_bin.values):\n",
    "        plot_list.append(hv.Curve(spk_observ, \n",
    "                                  extents=(0, 0, encode_settings.pos_bins[-1], max_prob)))\n",
    "\n",
    "        plot_list.append(hv.Points((pos_observ, [max_prob-0.01])))\n",
    "    return hv.Overlay(plot_list) * hv.Text(50,max_prob-0.05, \"num_spks: {num_spks}\\n\"\n",
    "                                           \"Timestamp: {timestamp}\\nTime: {time}\".\n",
    "                                           format(num_spks=num_spks, timestamp=time_bin_size*bin_id,\n",
    "                                                  time=time_bin_size*bin_id/30000))\n",
    "\n",
    "#Ind = Stream.define('stuff', ind=0)\n",
    "\n",
    "dmap = hv.DynamicMap(plot_observ, kdims=['big_bin', 'small_bin'], label=\"test\")\n",
    "#dmap = hv.DynamicMap(plot_observ, kdims=\n",
    "#                     [hv.Dimension('bin_id', range=(0, observ_obj['dec_bin'].iloc[-1]), step=1)])\n",
    "#dmap = hv.DynamicMap(plot_observ, kdims=\n",
    "#                     [hv.Dimension('bin_id', values=observ_obj['dec_bin'].unique())])\n",
    "\n",
    "#dmap.redim.values(bin_id=range(0, observ_obj['dec_bin'].iloc[-1]))\n",
    "dmap.redim.range(small_bin=(0, 1000), big_bin=(0, observ_obj['dec_bin'].iloc[-1]/1000 + 1))\n",
    "#dmap.redim.range(bin_id=(0, observ_obj['dec_bin'].iloc[-1]))\n",
    "#dmap.redim.values(bin_id=[4,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output backend='bokeh' size=400 holomap='scrubber'\n",
    "%%opts RGB { +framewise} [height=100 width=250 colorbar=True]\n",
    "%%opts Points {+framewise} [height=100 width=250] (marker='o' size=4 alpha=0.5)\n",
    "\n",
    "dec_viz = DecodeVisualizer(posteriors, linpos=lin_obj, enc_settings=encode_settings)\n",
    "\n",
    "dec_viz.plot_all_dynamic(stream=hv.streams.RangeXY(), plt_range=10, slide=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Polygons (fill_color='grey' fill_alpha=0.4 color='grey'  )\n",
    "plot = dec_viz.plot_decode_image(2500)\n",
    "poly = hv.Polygons([{('x','y'):[(2501, -0), (2502, -0), (2502, 450), (2501, 450)]}, {('x','y'): [(2504, -0), (2505, -0), (2505, 450), (2504, 450)]}])\n",
    "plot * poly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.help(hv.Bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}