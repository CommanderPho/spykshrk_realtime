{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import scipy.signal\n",
    "\n",
    "from spykshrk.realtime.decoder_process import PointProcessDecoder\n",
    "\n",
    "import spykshrk.realtime.simulator.nspike_data as nspike_data\n",
    "\n",
    "#pd.set_option('float_format', '{:,.2f}'.format)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "#pd.set_option('display.width', 180)\n",
    "\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "\n",
    "def normal2D(x, y, sig):\n",
    "    return np.exp(-(np.power(x, 2.) + np.power(y, 2.)) / (2 * np.power(sig, 2.)))\n",
    "\n",
    "\n",
    "def apply_no_anim_boundary(x_bins, bounds, image):\n",
    "    # no-animal boundary\n",
    "    boundary_ind = np.searchsorted(x_bins, bounds, side='right')\n",
    "    boundary_ind = np.reshape(boundary_ind, [3,2])\n",
    "\n",
    "    for bounds in boundary_ind:\n",
    "        if image.ndim == 1:\n",
    "            image[bounds[0]:bounds[1]] = 0\n",
    "        elif image.ndim == 2:\n",
    "            image[bounds[0]:bounds[1], :] = 0\n",
    "            image[:, bounds[0]:bounds[1]] = 0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load merged rec HDF store based on config\n",
    "\n",
    "config_file = '/opt/data36/daliu/realtime/spykshrk/dec_100uv/bond.config.json'\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "hdf_file = os.path.join(config['files']['output_dir'],\n",
    "                        '{}.rec_merged.h5'.format(config['files']['prefix']))\n",
    "\n",
    "store = pd.HDFStore(hdf_file, mode='r')\n",
    "spike_decode = store['rec_3']\n",
    "stim_lockout = store['rec_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stim_lockout_ranges = stim_lockout.pivot(index='lockout_num',columns='lockout_state', values='timestamp')\n",
    "stim_lockout_ranges = stim_lockout_ranges.reindex(columns=[1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get table with decode for each spike and generate decode bin mask\n",
    "\n",
    "dec_bin_size = 3000     # Decode bin size in samples (usually 30kHz)\n",
    "\n",
    "x_no_anim_bounds = [69, 150, 150+102, 300, 300+104, 450]\n",
    "\n",
    "dec_bins = np.floor((spike_decode['timestamp'] - spike_decode['timestamp'][0])/dec_bin_size).astype('int')\n",
    "spike_decode['dec_bin'] = dec_bins\n",
    "\n",
    "\n",
    "pos_upper = config['encoder']['position']['upper']\n",
    "pos_lower = config['encoder']['position']['lower']\n",
    "pos_num_bins = config['encoder']['position']['bins']\n",
    "pos_bin_delta = ((pos_upper - pos_lower) / pos_num_bins)\n",
    "\n",
    "x_bins = np.linspace(0, pos_bin_delta*(pos_num_bins-1), pos_num_bins)\n",
    "x_bin_edges = np.linspace(0, pos_bin_delta*(pos_num_bins), pos_num_bins+1)\n",
    "\n",
    "pos_kernel = gaussian(x_bins, x_bins[int(len(x_bins)/2)], 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get real position\n",
    "\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform position into simpler table with only linear position\n",
    "pos_data_time = pos_data.loc[:, 'time']\n",
    "\n",
    "pos_data_linpos = pos_data.loc[:,'lin_dist_well']\n",
    "pos_data_linpos.loc[:, 'lin_vel_center'] = pos_data.loc[:,('lin_vel', 'well_center')]\n",
    "pos_data_linpos.loc[:, 'seg_idx'] = pos_data.loc[:,('seg_idx', 0)]\n",
    "pos_data_linpos.loc[:,'timestamps'] = pos_data_time*30000\n",
    "pos_data_linpos = pos_data_linpos.set_index('timestamps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert real pos to realtime system linear map (single linear coordinate)\n",
    "\n",
    "center_pos_flat = pos_data_linpos[pos_data_linpos['seg_idx'] == 1]['well_center']\n",
    "left_pos_flat = pos_data_linpos[(pos_data_linpos['seg_idx'] == 2) | \n",
    "                                (pos_data_linpos['seg_idx'] == 3)]['well_left'] + 150\n",
    "right_pos_flat = pos_data_linpos[(pos_data_linpos['seg_idx'] == 4) | \n",
    "                                 (pos_data_linpos['seg_idx'] == 5)]['well_right'] + 300\n",
    "\n",
    "center_pos_flat.name = 'linpos_flat'\n",
    "left_pos_flat.name = 'linpos_flat'\n",
    "right_pos_flat.name = 'linpos_flat'\n",
    "\n",
    "linpos_flat = pd.concat([center_pos_flat, left_pos_flat, right_pos_flat])\n",
    "linpos_flat = linpos_flat.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compute artificial gaussian state transition matrix\n",
    "\n",
    "# Setup transition matrix\n",
    "transition_mat = np.ones([pos_num_bins, pos_num_bins])\n",
    "for bin_ii in range(pos_num_bins):\n",
    "    transition_mat[bin_ii, :] = gaussian(x_bins, x_bins[bin_ii], 3)\n",
    "\n",
    "# uniform offset\n",
    "uniform_gain = 0.01\n",
    "uniform_dist = np.ones(transition_mat.shape)\n",
    "\n",
    "# normalize transition matrix\n",
    "transition_mat = transition_mat/( transition_mat.sum(axis=0)[None,:])\n",
    "    \n",
    "#normalize uniform offset\n",
    "uniform_dist = uniform_dist/( uniform_dist.sum(axis=0)[None,:])\n",
    "    \n",
    "# apply uniform offset\n",
    "transition_mat = transition_mat * (1 - uniform_gain) + uniform_dist * uniform_gain \n",
    "\n",
    "    \n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(transition_mat, cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "spike_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pp_decoder = PointProcessDecoder(pos_range=[config['encoder']['position']['lower'],\n",
    "                                                 config['encoder']['position']['upper']],\n",
    "                                      pos_bins=config['encoder']['position']['bins'],\n",
    "                                      time_bin_size=config['pp_decoder']['bin_size'])\n",
    "\n",
    "pp_decoder.select_ntrodes(config['simulator']['nspike_animal_info']['tetrodes'])\n",
    "\n",
    "num_time_bins = spike_decode.loc[:,'dec_bin'].max()\n",
    "\n",
    "groups = spike_decode.groupby('dec_bin')\n",
    "\n",
    "last_bin_id = 0\n",
    "\n",
    "spykshrk_posteriors = np.zeros([num_time_bins+1, pos_num_bins])\n",
    "\n",
    "for bin_id, spikes_in_bin in groups:\n",
    "    if last_bin_id <= bin_id - 1:\n",
    "        for bin_no_spk_id in range(last_bin_id + 1, bin_id):\n",
    "            posterior = pp_decoder.increment_no_spike_bin()\n",
    "            spykshrk_posteriors[bin_no_spk_id, :] = posterior\n",
    "        \n",
    "    for ntrode_id, dec in zip(spikes_in_bin.loc[:, 'ntrode_id'].values, \n",
    "                   spikes_in_bin.loc[:, 'x0': 'x{:d}'.format(pos_num_bins-1)].values):\n",
    "        pp_decoder.add_observation(ntrode_id, dec)\n",
    "        \n",
    "    posterior = pp_decoder.increment_bin()\n",
    "    spykshrk_posteriors[bin_id, :] = posterior\n",
    "    last_bin_id = bin_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loop through each bin and generate the observation distribution from spikes in bin\n",
    "\n",
    "dec_bin_ids = np.unique(dec_bins)\n",
    "dec_est = np.zeros([dec_bin_ids[-1]+1, pos_num_bins])\n",
    "\n",
    "start_bin_time = np.floor(spike_decode['timestamp'][0] / dec_bin_size) * dec_bin_size\n",
    "dec_bin_times = np.arange(start_bin_time, start_bin_time + dec_bin_size * len(dec_est), dec_bin_size)\n",
    "\n",
    "# initialize conditional intensity function\n",
    "firing_rate = {ntrode_id: np.zeros(pos_num_bins) for ntrode_id in spike_decode['ntrode_id'].unique()}\n",
    "\n",
    "groups = spike_decode.groupby('dec_bin')\n",
    "bin_num_spikes = [0] * len(dec_est)\n",
    "\n",
    "for bin_id, spikes_in_bin in groups:\n",
    "    dec_in_bin = np.ones(pos_num_bins)\n",
    "    \n",
    "    \n",
    "    bin_num_spikes[bin_id] = len(spikes_in_bin)\n",
    "    \n",
    "    # Count spikes for occupancy firing rate (conditional intensity function)\n",
    "    for ntrode_id, pos in  spikes_in_bin.loc[:, ('ntrode_id', 'position')].values:\n",
    "        firing_rate[ntrode_id][np.searchsorted(x_bins, pos, side='right') - 1] += 1\n",
    "    \n",
    "    for dec_ii, dec in enumerate(spikes_in_bin.loc[:, 'x0':'x{:d}'.format(pos_num_bins-1)].values):\n",
    "        smooth_dec = np.convolve(dec, pos_kernel, mode='same')\n",
    "        dec_in_bin = dec_in_bin * smooth_dec\n",
    "        dec_in_bin = dec_in_bin / (np.sum(dec_in_bin) * pos_bin_delta)\n",
    "\n",
    "    dec_est[bin_id, :] = dec_in_bin\n",
    "    \n",
    "    \n",
    "# Smooth and normalize firing rate (conditional intensity function)\n",
    "for fr_key in firing_rate.keys():\n",
    "    firing_rate[fr_key] = np.convolve(firing_rate[fr_key], pos_kernel, mode='same')\n",
    "\n",
    "    firing_rate[fr_key] = apply_no_anim_boundary(x_bins, x_no_anim_bounds, firing_rate[fr_key])\n",
    "    \n",
    "    firing_rate[fr_key] = firing_rate[fr_key] / (firing_rate[fr_key].sum() * pos_bin_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Precompute prob of no spike from firing rate\n",
    "\n",
    "occupancy, occ_bin_edges = np.histogram(linpos_flat, bins=x_bin_edges, normed=True)\n",
    "\n",
    "occupancy = np.convolve(occupancy, pos_kernel, mode='same')\n",
    "\n",
    "prob_no_spike = {}\n",
    "for tet_id, tet_fr in firing_rate.items():\n",
    "    prob_no_spike[tet_id] = np.exp(-dec_bin_size/30000 * tet_fr / occupancy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the likelihood of each bin\n",
    "\n",
    "likelihoods = np.ones(dec_est.shape)\n",
    "\n",
    "\n",
    "for num_spikes, (dec_ind, dec_est_bin) in zip(bin_num_spikes, enumerate(dec_est)):\n",
    "    if num_spikes > 0:\n",
    "        likelihoods[dec_ind, :] = dec_est_bin\n",
    "        \n",
    "        for prob_no in prob_no_spike.values():\n",
    "            likelihoods[dec_ind, :] *= prob_no\n",
    "    else:\n",
    "        \n",
    "        for prob_no in prob_no_spike.values():\n",
    "            likelihoods[dec_ind, :] *= prob_no\n",
    "    \n",
    "    # Normalize\n",
    "    likelihoods[dec_ind, :] = likelihoods[dec_ind, :] / (likelihoods[dec_ind, :].sum() * pos_bin_delta)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iteratively calculate posterior\n",
    "last_posterior = np.ones(pos_num_bins)\n",
    "\n",
    "posteriors = np.zeros(dec_est.shape)\n",
    "    \n",
    "for like_ii, like in enumerate(likelihoods):\n",
    "    posteriors[like_ii, :] = like * (transition_mat * last_posterior).sum(axis=1)\n",
    "    posteriors[like_ii, :] = posteriors[like_ii, :] / (posteriors[like_ii, :].sum() * pos_bin_delta)\n",
    "    last_posterior = posteriors[like_ii, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_decode_2d(dec_est, dec_bin_times, stim_lockout_ranges, linpos_flat, plt_range):\n",
    "    stim_lockout_ranges_sec = stim_lockout_ranges/30000\n",
    "    stim_lockout_range_sec_sub = stim_lockout_ranges_sec[(stim_lockout_ranges_sec[1] > plt_range[0]) & (stim_lockout_ranges_sec[0] < plt_range[1])]\n",
    "    \n",
    "    plt.imshow(dec_est[(dec_bin_times > plt_range[0]*30000) & (dec_bin_times < plt_range[1]*30000)].transpose(), \n",
    "               extent=[plt_range[0], plt_range[1], 0, 450], origin='lower', aspect='auto', cmap='hot', zorder=0)\n",
    "\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Plot linear position\n",
    "    linpos_index_s = linpos_flat.index / 30000\n",
    "    index_mask = (linpos_index_s > plt_range[0]) & (linpos_index_s < plt_range[1])\n",
    "\n",
    "    plt.plot(linpos_index_s[index_mask],\n",
    "             linpos_flat.values[index_mask], 'c.', zorder=1, markersize=5)\n",
    "\n",
    "    \n",
    "    plt.plot(stim_lockout_range_sec_sub.values.transpose(), np.tile([[440], [440]], [1, len(stim_lockout_range_sec_sub)]), 'c-*' )\n",
    "\n",
    "    for stim_lockout in stim_lockout_range_sec_sub.values:\n",
    "        plt.axvspan(stim_lockout[0], stim_lockout[1], facecolor='#AAAAAA', alpha=0.3)\n",
    "\n",
    "    plt.plot(plt_range, [74, 74], '--', color='gray')\n",
    "    plt.plot(plt_range, [148, 148], '--', color='gray')\n",
    "    plt.plot(plt_range, [256, 256], '--', color='gray')\n",
    "    plt.plot(plt_range, [298, 298], '--', color='gray')\n",
    "    plt.plot(plt_range, [407, 407], '--', color='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_bin_times/30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt_ranges = [[2461 + 800, 2461+900]]\n",
    "             \n",
    "for plt_range in plt_ranges:\n",
    "    \n",
    "    plt.figure(figsize=[100,20])\n",
    "    plt.subplot(2,1,1)\n",
    "    plot_decode_2d(spykshrk_posteriors, dec_bin_times, stim_lockout_ranges, linpos_flat, plt_range)\n",
    "    plt.subplot(2,1,2)\n",
    "    plot_decode_2d(posteriors, dec_bin_times, stim_lockout_ranges, linpos_flat, plt_range)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}