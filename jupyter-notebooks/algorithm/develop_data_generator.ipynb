{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import holoviews as hv\n",
    "\n",
    "import json\n",
    "import functools\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.data_containers import FlatLinearPosition, SpikeFeatures, \\\n",
    "        EncodeSettings, pos_col_format, SpikeObservation\n",
    "from spykshrk.franklab.pp_decoder.util import normal_pdf_int_lookup\n",
    "\n",
    "hv.extension('matplotlib')\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "except:\n",
    "    print(\"No cluster or client\")\n",
    "    \n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=15)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UnitGenerator:\n",
    "    def __init__(self, elec_grp, mark_mean, mark_cov, pos_mean, pos_var, peak_fr, sampling_rate):\n",
    "        self.elec_grp = elec_grp\n",
    "        self.mark_mean = mark_mean\n",
    "        self.mark_cov = mark_cov\n",
    "        self.pos_mean = pos_mean\n",
    "        self.pos_var = pos_var\n",
    "        self.rv_marks = sp.stats.multivariate_normal(mean=mark_mean, cov=np.diag(mark_cov))\n",
    "        self.rv_pos = sp.stats.norm(loc=pos_mean, scale=pos_var)\n",
    "        self.peak_fr = peak_fr\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "    def simulate_spikes_over_pos(self, linpos_flat):\n",
    "        prob_field = self.rv_pos.pdf(linpos_flat['linpos_flat'].values)/self.rv_pos.pdf(self.pos_mean)\n",
    "        \n",
    "        spike_train = sp.stats.bernoulli(p=self.peak_fr/self.sampling_rate * prob_field).rvs()\n",
    "        \n",
    "        \n",
    "        marks = np.atleast_2d(self.rv_marks.rvs(sum(spike_train))).astype('i4')\n",
    "        \n",
    "        sample_num = np.nonzero(spike_train)[0]\n",
    "\n",
    "        time_ind = linpos_flat.index[sample_num]\n",
    "        ind_levels = time_ind.levels.copy()\n",
    "        ind_levels.append([self.elec_grp])\n",
    "        ind_labels = time_ind.labels.copy()\n",
    "        ind_labels.append([0]*len(time_ind))\n",
    "        ind_names = time_ind.names.copy()\n",
    "        ind_names.append('elec_grp')\n",
    "        \n",
    "        new_ind = pd.MultiIndex(levels=ind_levels, labels=ind_labels, names=ind_names)\n",
    "        new_ind = new_ind.reorder_levels(['day', 'epoch', 'elec_grp', 'timestamp', 'time'])\n",
    "        #new_ind = new_ind.sortlevel(['day', 'epoch', 'elec_grp', 'timestamp', 'time'])\n",
    "\n",
    "        \n",
    "        spk_amp = SpikeFeatures(marks, columns=['c00', 'c01', 'c02', 'c03'],\n",
    "                                index=new_ind)\n",
    "                                                             \n",
    "        \n",
    "        return spk_amp\n",
    "    \n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encode_settings = AttrDict({'pos_bins': np.arange(0,100,1), \n",
    "                            'pos_kernel_std': 10, \n",
    "                            'mark_kernel_std': 40, \n",
    "                            'pos_num_bins': 100})\n",
    "\n",
    "sampling_rate = 1000\n",
    "\n",
    "pos_time = np.arange(0,20000,1)\n",
    "pos_run = 100*np.cos(pos_time/(500*np.pi))\n",
    "pos_vel = np.concatenate([[0], np.diff(pos_run) * sampling_rate])\n",
    "\n",
    "linpos_flat_obj = FlatLinearPosition.from_numpy_single_epoch(1, 1, pos_time, pos_run, pos_vel, sampling_rate)\n",
    "\n",
    "mark_mean_range = [20,1000]\n",
    "mark_cov_range = [200,500]\n",
    "num_marks = 4\n",
    "num_units = 10\n",
    "firing_rate_range = [20,100]\n",
    "\n",
    "pos_range = [0, 100]\n",
    "pos_var_range = [10,40]\n",
    "\n",
    "mark_kernel = 40\n",
    "pos_kernel = 10\n",
    "\n",
    "unit_mean = np.random.randint(*mark_mean_range, [num_units, num_marks])\n",
    "unit_cov = np.random.randint(*mark_cov_range, [num_units, num_marks])\n",
    "unit_pos_mean = np.random.randint(*pos_range, [num_units])\n",
    "unit_pos_var = np.random.randint(*pos_var_range, [num_units])\n",
    "unit_fr = np.random.randint(*pos_var_range, [num_units])\n",
    "\n",
    "\n",
    "\n",
    "units = {}\n",
    "spk_amps = pd.DataFrame()\n",
    "for unit_ii in range(num_units):\n",
    "    units[unit_ii] = UnitGenerator(elec_grp=1,\n",
    "                                   mark_mean=unit_mean[unit_ii,:], mark_cov=unit_cov[unit_ii,:], \n",
    "                                   pos_mean=unit_pos_mean[unit_ii], pos_var=unit_pos_var[unit_ii], \n",
    "                                   peak_fr=unit_fr[unit_ii], sampling_rate=sampling_rate)\n",
    "\n",
    "    unit_marks = units[unit_ii].simulate_spikes_over_pos(linpos_flat_obj)\n",
    "    spk_amps = spk_amps.append(unit_marks)\n",
    "spk_amps.sort_index(level='timestamp', inplace=True)\n",
    "\n",
    "spk_amps.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def compute_observ_tet(dec_spk, enc_spk, tet_lin_pos, encode_settings):\n",
    "    \n",
    "    pos_distrib_tet = sp.stats.norm.pdf(np.expand_dims(encode_settings.pos_bins, 0),\n",
    "                                        np.expand_dims(tet_lin_pos['linpos_flat'],1), \n",
    "                                        encode_settings.pos_kernel_std)\n",
    "\n",
    "    mark_contrib = normal_pdf_int_lookup(np.expand_dims(dec_spk, 1), \n",
    "                                         np.expand_dims(enc_spk,0), \n",
    "                                         encode_settings.mark_kernel_std)\n",
    "\n",
    "    all_contrib = np.prod(mark_contrib, axis=2)\n",
    "\n",
    "    observ = np.matmul(all_contrib, pos_distrib_tet)\n",
    "    \n",
    "    # normalize each row\n",
    "    observ = observ / observ.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    ret_df = pd.DataFrame(observ, index=dec_spk.index, \n",
    "                          columns=[pos_col_format(pos_ii, observ.shape[1]) \n",
    "                                   for pos_ii in range(observ.shape[1])])\n",
    "    return ret_df\n",
    "\n",
    "\n",
    "grp = spk_amps.groupby('elec_grp')\n",
    "observations = {}\n",
    "task = []\n",
    "chunksize = 100\n",
    "for tet_id, spk_tet in grp:\n",
    "    spk_tet.index = spk_tet.index.droplevel('elec_grp')\n",
    "    tet_lin_pos = linpos_flat_obj.reindex(spk_tet.index)\n",
    "    \n",
    "    # Velocity threshold on spikes and position\n",
    "    #tet_lin_pos_thresh = tet_lin_pos.get_above_velocity(10.)\n",
    "    #spk_tet_thresh = spk_tet.reindex(tet_lin_pos_thresh.index)\n",
    "    tet_lin_pos_thresh = tet_lin_pos\n",
    "    spk_tet_thresh = spk_tet\n",
    "    \n",
    "    # Decode from all spikes\n",
    "    dask_spk_tet = dd.from_pandas(spk_tet.get_simple_index(), chunksize=chunksize)\n",
    "    \n",
    "    df_meta = pd.DataFrame([], columns=[pos_col_format(ii, encode_settings.pos_num_bins) \n",
    "                                        for ii in range(encode_settings.pos_num_bins)])\n",
    "    \n",
    "    # Setup decode of all spikes from encoding of velocity threshold spikes\n",
    "    task.append(dask_spk_tet.map_partitions(functools.partial(compute_observ_tet, enc_spk=spk_tet_thresh,\n",
    "                                                              tet_lin_pos=tet_lin_pos_thresh,\n",
    "                                                              encode_settings=encode_settings), \n",
    "                                            meta=df_meta))\n",
    "    \n",
    "results = dask.compute(*task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tet_ids = np.unique(spk_amps.index.get_level_values('elec_grp'))\n",
    "observ_tet_list = []\n",
    "grp = spk_amps.groupby('elec_grp')\n",
    "for tet_ii, (tet_id, grp_spk) in enumerate(grp):\n",
    "    tet_result = results[tet_ii]\n",
    "    tet_result.set_index(grp_spk.index, inplace=True)\n",
    "    observ_tet_list.append(tet_result)\n",
    "\n",
    "observ = pd.concat(observ_tet_list)\n",
    "observ_obj = SpikeObservation.from_df(observ.sort_index(level=['day', 'epoch', \n",
    "                                                               'timestamp', 'elec_grp']), )\n",
    "\n",
    "observ_obj['elec_grp'] = observ_obj.index.get_level_values('elec_grp')\n",
    "observ_obj.index = observ_obj.index.droplevel('elec_grp')\n",
    "\n",
    "observ_obj['position'] = (linpos_flat_obj['linpos_flat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "observ_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Scatter3D [fig_size=200]\n",
    "\n",
    "grp = spk_amps.groupby('elec_grp')\n",
    "\n",
    "\n",
    "scatter = [hv.Scatter3D(elec_spk.values) for elec_id, elec_spk in grp]\n",
    "\n",
    "overlay = hv.Overlay(scatter)\n",
    "\n",
    "overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hv.Scatter3D(marks[0][:,0:3])\n",
    "hv.Scatter3D(marks[1][:,0:3])\n"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}