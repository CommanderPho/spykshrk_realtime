{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import holoviews as hv\n",
    "\n",
    "import json\n",
    "import functools\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.data_containers import FlatLinearPosition, SpikeFeatures, \\\n",
    "        EncodeSettings, pos_col_format, SpikeObservation\n",
    "from spykshrk.franklab.pp_decoder.util import normal_pdf_int_lookup, gaussian\n",
    "from spykshrk.franklab.pp_decoder.pp_clusterless import OfflinePPDecoder\n",
    "from spykshrk.franklab.pp_decoder.visualization import DecodeVisualizer\n",
    "\n",
    "hv.extension('matplotlib')\n",
    "hv.extension('bokeh')\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "except:\n",
    "    print(\"No cluster or client\")\n",
    "    \n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=15)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UnitGenerator:\n",
    "    def __init__(self, elec_grp_id, mark_mean, mark_cov, pos_mean, pos_var, peak_fr, sampling_rate):\n",
    "        self.elec_grp_id = elec_grp_id\n",
    "        self.mark_mean = mark_mean\n",
    "        self.mark_cov = mark_cov\n",
    "        self.pos_mean = pos_mean\n",
    "        self.pos_var = pos_var\n",
    "        self.rv_marks = sp.stats.multivariate_normal(mean=mark_mean, cov=np.diag(mark_cov))\n",
    "        self.rv_pos = sp.stats.norm(loc=pos_mean, scale=pos_var)\n",
    "        self.peak_fr = peak_fr\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "    def simulate_spikes_over_pos(self, linpos_flat):\n",
    "        prob_field = self.rv_pos.pdf(linpos_flat['linpos_flat'].values)/self.rv_pos.pdf(self.pos_mean)\n",
    "        \n",
    "        spike_train = sp.stats.bernoulli(p=self.peak_fr/self.sampling_rate * prob_field).rvs()\n",
    "        \n",
    "        \n",
    "        marks = np.atleast_2d(self.rv_marks.rvs(sum(spike_train))).astype('i4')\n",
    "        \n",
    "        sample_num = np.nonzero(spike_train)[0]\n",
    "\n",
    "        time_ind = linpos_flat.index[sample_num]\n",
    "        ind_levels = time_ind.levels.copy()\n",
    "        ind_levels.append([self.elec_grp_id])\n",
    "        ind_labels = time_ind.labels.copy()\n",
    "        ind_labels.append([0]*len(time_ind))\n",
    "        ind_names = time_ind.names.copy()\n",
    "        ind_names.append('elec_grp_id')\n",
    "        \n",
    "        new_ind = pd.MultiIndex(levels=ind_levels, labels=ind_labels, names=ind_names)\n",
    "        new_ind = new_ind.reorder_levels(['day', 'epoch', 'elec_grp_id', 'timestamp', 'time'])\n",
    "        #new_ind = new_ind.sortlevel(['day', 'epoch', 'elec_grp', 'timestamp', 'time'])\n",
    "\n",
    "        \n",
    "        spk_amp = SpikeFeatures(marks, columns=['c00', 'c01', 'c02', 'c03'],\n",
    "                                index=new_ind)\n",
    "                                                             \n",
    "        mark_linpos = linpos_flat.iloc[sample_num]\n",
    "        mark_linpos['elec_grp_id'] = self.elec_grp_id\n",
    "        mark_linpos.set_index('elec_grp_id', append=True, inplace=True)\n",
    "        mark_linpos = mark_linpos.reorder_levels(['day','epoch','elec_grp_id','timestamp','time'])\n",
    "        \n",
    "        return spk_amp, mark_linpos, prob_field\n",
    "    \n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encode_settings = AttrDict({'sampling_rate': 1000,\n",
    "                            'pos_bins': np.arange(0,100,1),\n",
    "                            'pos_bin_edges': np.arange(0,100.1,1),\n",
    "                            'pos_bin_delta': 1,\n",
    "                            'pos_kernel': sp.stats.norm.pdf(np.arange(0,100,1), 50, 1),\n",
    "                            'pos_kernel_std': 1, \n",
    "                            'mark_kernel_std': 20, \n",
    "                            'pos_num_bins': 100,\n",
    "                            'pos_col_names': [pos_col_format(ii, 100) for ii in range(100)],\n",
    "                            'arm_coordinates': [[0,100]]})\n",
    "\n",
    "decode_settings = AttrDict({'trans_smooth_std': 5,\n",
    "                            'trans_uniform_gain': 0.001,\n",
    "                            'time_bin_size': 10})\n",
    "                            \n",
    "\n",
    "sampling_rate = 1000\n",
    "\n",
    "pos_time = np.arange(0,100000,1)\n",
    "pos_run = 50*np.cos(pos_time[0:17272]/(500*np.pi))+50\n",
    "pos_run = np.append(pos_run, ([pos_run[-1]]*39478))\n",
    "pos_run = np.append(pos_run, 50*np.cos(pos_time[56750:100000]/(500*np.pi))+50)\n",
    "pos_vel = np.concatenate([[0], np.diff(pos_run) * sampling_rate])\n",
    "\n",
    "linpos_flat_obj = FlatLinearPosition.from_numpy_single_epoch(1, 1, pos_time, pos_run, pos_vel, sampling_rate)\n",
    "\n",
    "mark_mean_range = [20,1000]\n",
    "mark_cov_range = [200,500]\n",
    "num_marks = 4\n",
    "num_units = 50\n",
    "firing_rate_range = [20,50]\n",
    "\n",
    "pos_field_range = [0, 100]\n",
    "pos_field_var_range = [5,10]\n",
    "\n",
    "unit_mean = np.random.randint(*mark_mean_range, [num_units, num_marks])\n",
    "unit_cov = np.random.randint(*mark_cov_range, [num_units, num_marks])\n",
    "\n",
    "#unit_pos_mean = np.random.randint(*pos_field_range, [num_units])\n",
    "#unit_pos_var = np.random.randint(*pos_field_var_range, [num_units])\n",
    "\n",
    "unit_pos_mean = np.linspace(*pos_field_range, num_units)\n",
    "unit_pos_var = np.array([pos_field_range[1]/num_units*2]*num_units)\n",
    "\n",
    "unit_fr = np.random.randint(*firing_rate_range, [num_units])\n",
    "\n",
    "\n",
    "\n",
    "units = {}\n",
    "unit_spks = {}\n",
    "spk_amps = pd.DataFrame()\n",
    "for unit_ii in range(num_units):\n",
    "    units[unit_ii] = UnitGenerator(elec_grp_id=1,\n",
    "                                   mark_mean=unit_mean[unit_ii,:], mark_cov=unit_cov[unit_ii,:], \n",
    "                                   pos_mean=unit_pos_mean[unit_ii], pos_var=unit_pos_var[unit_ii], \n",
    "                                   peak_fr=unit_fr[unit_ii], sampling_rate=sampling_rate)\n",
    "\n",
    "    unit_marks, mark_pos, field = units[unit_ii].simulate_spikes_over_pos(linpos_flat_obj)\n",
    "    unit_spks[unit_ii] = unit_marks.merge(mark_pos, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "    spk_amps = spk_amps.append(unit_marks)\n",
    "spk_amps.sort_index(level='timestamp', inplace=True)\n",
    "\n",
    "spk_amps.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=200 backend='matplotlib'\n",
    "%%opts Points [aspect=2] (marker='.')\n",
    "\n",
    "hv.Points(pos_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output backend='matplotlib'\n",
    "%opts Scatter3D {+framewise}\n",
    "%opts Overlay {+framewise}\n",
    "\n",
    "from holoviews.streams import Stream, param\n",
    "\n",
    "\n",
    "def mark_plots(elevation, azimuth):\n",
    "    %%output backend='matplotlib'\n",
    "    scatter = [hv.Scatter3D(mark_pos.loc[:,['linpos_flat','c01','c02']])\n",
    "               for elec_id, mark_pos in unit_spks.items()]\n",
    "    overlay = hv.Overlay(scatter)\n",
    "    overlay = overlay.opts({'Scatter3D':{'plot': {'fig_size':400, 'azimuth': int(azimuth), \n",
    "                                                  'elevation': int(elevation)},\n",
    "                                         'norm': {'framewise':True}}})\n",
    "    return overlay\n",
    "\n",
    "\n",
    "#holo = hv.HoloMap({(e,a): mark_plots(e,a) for e in range(0, 181, 20)\n",
    "#                   for a in range(-90,91,20)}, kdims=['e','a'])\n",
    "#holo\n",
    "\n",
    "dmap = hv.DynamicMap(callback=mark_plots, kdims=['elevation', 'azimuth'], cache_size=1)\n",
    "dmap = dmap.redim.values(elevation=range(0,181,5),\n",
    "                         azimuth=range(-90,91,5)).opts(norm=dict(framewise=True))\n",
    "dmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def compute_observ_tet(dec_spk, enc_spk, tet_lin_pos, occupancy, encode_settings):\n",
    "    \n",
    "    pos_distrib_tet = sp.stats.norm.pdf(np.expand_dims(encode_settings.pos_bins, 0),\n",
    "                                        np.expand_dims(tet_lin_pos['linpos_flat'],1), \n",
    "                                        encode_settings.pos_kernel_std)\n",
    "\n",
    "    mark_contrib = normal_pdf_int_lookup(np.expand_dims(dec_spk, 1), \n",
    "                                         np.expand_dims(enc_spk,0), \n",
    "                                         encode_settings.mark_kernel_std)\n",
    "\n",
    "    all_contrib = np.prod(mark_contrib, axis=2)\n",
    "\n",
    "    observ = np.matmul(all_contrib, pos_distrib_tet)\n",
    "    \n",
    "    # occupancy normalize\n",
    "    observ = observ / occupancy\n",
    "    \n",
    "    # normalize each row\n",
    "    observ = observ / observ.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    ret_df = pd.DataFrame(observ, index=dec_spk.index, \n",
    "                          columns=[pos_col_format(pos_ii, observ.shape[1]) \n",
    "                                   for pos_ii in range(observ.shape[1])])\n",
    "    return ret_df\n",
    "\n",
    "\n",
    "occ, _ = np.histogram(a=linpos_flat_obj['linpos_flat'], bins=encode_settings.pos_bin_edges,normed=True)\n",
    "occ = np.convolve(occ, encode_settings.pos_kernel)[int(len(occ)/2):int(len(occ)*3/2)]\n",
    "\n",
    "grp = spk_amps.groupby('elec_grp_id')\n",
    "observations = {}\n",
    "task = []\n",
    "chunksize = 100\n",
    "for tet_id, spk_tet in grp:\n",
    "    spk_tet.index = spk_tet.index.droplevel('elec_grp_id')\n",
    "    tet_lin_pos = linpos_flat_obj.reindex(spk_tet.index)\n",
    "    \n",
    "    # Velocity threshold on spikes and position\n",
    "    #tet_lin_pos_thresh = tet_lin_pos.get_above_velocity(10.)\n",
    "    #spk_tet_thresh = spk_tet.reindex(tet_lin_pos_thresh.index)\n",
    "    tet_lin_pos_thresh = tet_lin_pos\n",
    "    spk_tet_thresh = spk_tet\n",
    "    \n",
    "    # Decode from all spikes\n",
    "    dask_spk_tet = dd.from_pandas(spk_tet.get_simple_index(), chunksize=chunksize)\n",
    "    \n",
    "    df_meta = pd.DataFrame([], columns=[pos_col_format(ii, encode_settings.pos_num_bins) \n",
    "                                        for ii in range(encode_settings.pos_num_bins)])\n",
    "    \n",
    "    # Setup decode of all spikes from encoding of velocity threshold spikes\n",
    "    task.append(dask_spk_tet.map_partitions(functools.partial(compute_observ_tet, enc_spk=spk_tet_thresh,\n",
    "                                                              tet_lin_pos=tet_lin_pos_thresh,\n",
    "                                                              occupancy=occ,\n",
    "                                                              encode_settings=encode_settings), \n",
    "                                            meta=df_meta))\n",
    "    \n",
    "results = dask.compute(*task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output backend='bokeh'\n",
    "%%opts Histogram [height=300, width=600]\n",
    "hist1 = hv.Histogram((occ, encode_settings.pos_bin_edges))\n",
    "\n",
    "hist2 = hv.Histogram(np.histogram(a=linpos_flat_obj['linpos_flat'], \n",
    "                                  bins=encode_settings.pos_bin_edges,normed=True))\n",
    "\n",
    "layout = hv.Layout(hist1 + hist2).cols(1)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encode_settings.pos_bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tet_ids = np.unique(spk_amps.index.get_level_values('elec_grp_id'))\n",
    "observ_tet_list = []\n",
    "grp = spk_amps.groupby('elec_grp_id')\n",
    "for tet_ii, (tet_id, grp_spk) in enumerate(grp):\n",
    "    tet_result = results[tet_ii]\n",
    "    tet_result.set_index(grp_spk.index, inplace=True)\n",
    "    observ_tet_list.append(tet_result)\n",
    "\n",
    "observ = pd.concat(observ_tet_list)\n",
    "observ_obj = SpikeObservation(observ.sort_index(level=['day', 'epoch', \n",
    "                                                               'timestamp', 'elec_grp_id']), )\n",
    "\n",
    "observ_obj['elec_grp_id'] = observ_obj.index.get_level_values('elec_grp_id')\n",
    "observ_obj.index = observ_obj.index.droplevel('elec_grp_id')\n",
    "\n",
    "observ_obj['position'] = (linpos_flat_obj['linpos_flat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output backend='matplotlib' size=200\n",
    "%%opts Points (s=400 marker='x')\n",
    "\n",
    "sel_distrib = observ_obj.loc[:, pos_col_format(0,encode_settings.pos_num_bins):         \n",
    "                                 pos_col_format(encode_settings.pos_num_bins-1,\n",
    "                                                encode_settings.pos_num_bins)]\n",
    "    \n",
    "sel_pos = observ_obj.loc[:, 'position']\n",
    "\n",
    "max = sel_distrib.max().max()\n",
    "    \n",
    "def plot_observ(ind):\n",
    "    \n",
    "        \n",
    "    plot_list = []\n",
    "    for ii in range(5):\n",
    "        plot_list.append(hv.Curve(sel_distrib.iloc[ind+ii], extents=(0, 0, 100, max)))\n",
    "        plot_list.append(hv.Points((sel_pos.iloc[ind+ii], [0.005])))\n",
    "    return hv.Overlay(plot_list)\n",
    "        \n",
    "#Ind = Stream.define('stuff', ind=0)\n",
    "\n",
    "dmap = hv.DynamicMap(plot_observ, kdims=['ind'])\n",
    "dmap.redim.values(ind=list(range(0, len(observ_obj)-5, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run PP decoding algorithm\n",
    "time_bin_size = 30\n",
    "\n",
    "decoder = OfflinePPDecoder(lin_obj=linpos_flat_obj, observ_obj=observ_obj,\n",
    "                           encode_settings=encode_settings, decode_settings=decode_settings, \n",
    "                           which_trans_mat='learned', time_bin_size=time_bin_size)\n",
    "\n",
    "posteriors = decoder.run_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output backend='bokeh' size=400 holomap='scrubber'\n",
    "%%opts RGB { +framewise} [height=100 width=250 colorbar=True]\n",
    "%%opts Points {+framewise} [height=100 width=250] (marker='o' size=4 alpha=0.5)\n",
    "\n",
    "dec_viz = DecodeVisualizer(posteriors, linpos=linpos_flat_obj, enc_settings=encode_settings)\n",
    "\n",
    "dec_viz.plot_all_dynamic(stream=hv.streams.RangeXY(), plt_range=100, slide=10)\n"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}