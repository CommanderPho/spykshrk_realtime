{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start mysql docker: sudo docker-compose up -d\n",
    "\n",
    "import datajoint as dj\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorruptData(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.abspath(os.path.join(globals()['_dh'][0], '../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_cred_filename = os.path.join(root_path, 'datajoint/local_cred.ini')\n",
    "with open(local_cred_filename) as f:\n",
    "    local_cred = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_filename = \"~/\"\n",
    "\n",
    "dj.config['database.host'] = local_cred['host']\n",
    "dj.config['database.user'] = local_cred['user']\n",
    "dj.config['database.password'] = local_cred['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.schema('franklab_nspike', locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@schema\n",
    "class Animal(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    anim_name: varchar(20)  #Name of animal\n",
    "    ---\n",
    "    anim_path_raw: varchar(200)\n",
    "    anim_path_mat: varchar(200)\n",
    "    \"\"\"\n",
    "\n",
    "@schema\n",
    "class Day(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Animal\n",
    "    day: int\n",
    "    ---\n",
    "    day_path_raw: varchar(200)\n",
    "    day_start_time_sec: float\n",
    "    day_end_time_sec: float\n",
    "    day_start_time_nspike: int\n",
    "    day_end_time_nspike: int\n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        \n",
    "        anim_name, anim_path_raw, anim_path_mat = (Animal() & key).fetch1('anim_name', 'anim_path_raw', 'anim_path_mat')\n",
    "        dir_names = os.listdir(anim_path_raw)\n",
    "        for dir_name in dir_names:\n",
    "            m = re.search('^{:s}(\\d*)$'.format(anim_name.lower()), dir_name)\n",
    "            if m:\n",
    "                day = int(m.groups()[0])\n",
    "                day_path_raw = os.path.join(anim_path_raw, dir_name)\n",
    "                times_path = os.path.join(day_path_raw, 'times.mat')\n",
    "                if os.path.isfile(times_path):\n",
    "                    times_mat = loadmat(times_path)\n",
    "                    time_ranges = times_mat['ranges']\n",
    "                    day_start_time_nspike = time_ranges[0][0]\n",
    "                    day_end_time_nspike = time_ranges[0][1]\n",
    "                    day_start_time_sec = day_start_time_nspike/10000\n",
    "                    day_end_time_sec = day_end_time_nspike/10000\n",
    "                    self.insert1({'anim_name': anim_name,\n",
    "                                  'day': day,\n",
    "                                  'day_path_raw': day_path_raw,\n",
    "                                  'day_start_time_sec': day_start_time_nspike,\n",
    "                                  'day_end_time_sec': day_end_time_nspike,\n",
    "                                  'day_start_time_nspike': day_start_time_sec,\n",
    "                                  'day_end_time_nspike': day_end_time_sec})\n",
    "                else:\n",
    "                    # Missing times.mat means data folder was not processed for spike sorting (matclust)\n",
    "                    pass\n",
    "\n",
    "@schema\n",
    "class Epoch(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Day\n",
    "    epoch_id: tinyint\n",
    "    ---\n",
    "    epoch_name: varchar(50)\n",
    "    epoch_time_str: varchar(50)\n",
    "    epoch_start_time_sec: float\n",
    "    epoch_end_time_sec: float\n",
    "    epoch_start_time_nspike: int\n",
    "    epoch_end_time_nspike: int\n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        day, day_path_raw = day_path_raw = (Day() & key).fetch1('day', 'day_path_raw')\n",
    "        try:\n",
    "            times_mat = loadmat(os.path.join(day_path_raw, 'times.mat'))\n",
    "            time_ranges = times_mat['ranges']\n",
    "            names = times_mat['names']\n",
    "            for epoch_id, epoch_time_range in enumerate(time_ranges[1:]):\n",
    "                epoch_start_time_nspike = epoch_time_range[0]\n",
    "                epoch_end_time_nspike = epoch_time_range[1]\n",
    "                epoch_start_time_sec = epoch_start_time_nspike/10000\n",
    "                epoch_end_time_sec = epoch_end_time_nspike/10000\n",
    "                name_entry = names[epoch_id + 1]\n",
    "                name_re = re.search('\\d*\\s*(\\w*)\\s*([0-9:-_]*)$', name_entry)\n",
    "                if name_re:\n",
    "                    epoch_name = name_re.groups()[0]\n",
    "                    epoch_time_str = name_re.groups()[1]\n",
    "                    self.insert1({'day': day, \n",
    "                                  'epoch_name': epoch_name,\n",
    "                                  'epoch_time_str': epoch_time_str,\n",
    "                                  'epoch_start_time_sec': epoch_start_time_sec,\n",
    "                                  'epoch_end_time_sec':epoch_start_time_sec,\n",
    "                                  'epoch_start_time_nspike': epoch_start_time_nspike,\n",
    "                                  'epoch_end_time_nspike': epoch_end_time_nspike\n",
    "                                 })\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            raise CorruptData('Missing {:s}.'.format((os.path.join(day_path_raw, 'times.mat'))))\n",
    "    \n",
    "@schema\n",
    "class Tetrode(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> Animal\n",
    "    elec_grp_id: tinyint\n",
    "    ---\n",
    "    tet_num_chan: tinyint unsigned\n",
    "    tet_valid_chan: tinyblob\n",
    "    tet_hemisphere: varchar(50)\n",
    "    tet_path_raw_part: varchar(200)\n",
    "    \"\"\"\n",
    "\n",
    "@schema\n",
    "class TetrodeEpoch(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> Tetrode\n",
    "    -> Epoch\n",
    "    ---\n",
    "    tet_depth: int\n",
    "    tet_num_cells: int\n",
    "    tet_area: varchar(50)\n",
    "    tet_subarea: varchar(50)\n",
    "    \"\"\"\n",
    "    \n",
    "@schema\n",
    "class LFP(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> TetrodeEpoch\n",
    "    ---\n",
    "    lfp_path_raw_part: varchar(200)\n",
    "    lfp_path_raw_abs: varchar(200)\n",
    "    lfp_path_eeg_part: varchar(200)\n",
    "    lfp_path_eeg_abs: varchar(200)\n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        print (key)\n",
    "        display((Animal() * Tetrode()) & key)\n",
    "     \n",
    "@schema\n",
    "class RippleInterval(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Epoch\n",
    "    algorithm: varchar(20)\n",
    "    ---\n",
    "    part_path: varchar(200)\n",
    "    path_abs: varchar(200)\n",
    "    \"\"\"\n",
    "    \n",
    "    class LFPSource(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> LFP\n",
    "        ---\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        print(key)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = Animal()\n",
    "day = Day()\n",
    "epoch = Epoch()\n",
    "tet = Tetrode()\n",
    "tet_ep = TetrodeEpoch()\n",
    "lfp = LFP()\n",
    "rip = RippleInterval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.insert1({'anim_name': 'Bond', 'anim_path_raw': '/opt/data/daliu/other/mkarlsso/bond/', 'anim_path_mat': '/opt/data/daliu/other/mkarlsso/Bon/'})\n",
    "display(anim)\n",
    "day.populate()\n",
    "display(day)\n",
    "epoch.populate()\n",
    "display(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_time in loadmat('/opt/data/daliu/other/mkarlsso/bond/bond03/times.mat')['ranges'][1:]:\n",
    "    print(epoch_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch.insert([{'day': 4, 'epoch_id': 0, 'epoch_name': 'sleep1', 'path_part': './', 'time_range_sec': [0,9]},\n",
    "              {'day': 4, 'epoch_id': 1, 'name': 'sleep1', 'path_part': './', 'time_range_sec': [10,19]}])\n",
    "\n",
    "display(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tet.insert([{'anim_name': 'Bond', 'elec_grp_id': 1, 'num_chan': 4, 'valid_chan': [0,1,2,3], 'path_part': './'},\n",
    "            {'anim_name': 'Bond', 'elec_grp_id': 2, 'num_chan': 4, 'valid_chan': [0,1,2,3], 'path_part': './'},\n",
    "            {'anim_name': 'Bond', 'elec_grp_id': 3, 'num_chan': 4, 'valid_chan': [0,1,2,3], 'path_part': './'}])\n",
    "tet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "day * epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp.insert([{'anim_name': 'Bond', 'day': 4, 'elec_grp_id': 1, 'epoch_id': 0, 'path_part': './01-149.eeg'},\n",
    "            {'anim_name': 'Bond', 'day': 4, 'elec_grp_id': 2, 'epoch_id': 0, 'path_part': './02-151.eeg'},\n",
    "            {'anim_name': 'Bond', 'day': 4, 'elec_grp_id': 3, 'epoch_id': 0, 'path_part': './03-100.eeg'}])\n",
    "lfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tet.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class Ripple(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Tetrode\n",
    "    rip_id: tinyint\n",
    "    ---\n",
    "    path\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rip = Ripple()\n",
    "rip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}