{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start mysql docker: sudo docker-compose up -d\n",
    "\n",
    "import datajoint as dj\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "import traceback\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorruptData(Exception):\n",
    "    pass\n",
    "\n",
    "class InconsistentData(Warning):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.abspath(os.path.join(globals()['_dh'][0], '../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_cred_filename = os.path.join(root_path, 'datajoint/local_cred.ini')\n",
    "with open(local_cred_filename) as f:\n",
    "    local_cred = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_filename = \"~/\"\n",
    "\n",
    "dj.config['database.host'] = local_cred['host']\n",
    "dj.config['database.user'] = local_cred['user']\n",
    "dj.config['database.password'] = local_cred['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn().cancel_transaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.schema('franklab_nspike', locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.drop()\n",
    "schema = dj.schema('franklab_nspike', locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@schema\n",
    "class Animal(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    anim_name: varchar(20)  #Name of animal\n",
    "    ---\n",
    "    anim_path_raw: varchar(200)\n",
    "    anim_path_mat: varchar(200)\n",
    "    \"\"\"\n",
    "\n",
    "@schema\n",
    "class Day(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Animal\n",
    "    day: int\n",
    "    ---\n",
    "    day_path_raw: varchar(200)\n",
    "    day_start_time_sec: float\n",
    "    day_end_time_sec: float\n",
    "    day_start_time_nspike: int\n",
    "    day_end_time_nspike: int\n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        \n",
    "        anim_name, anim_path_raw, anim_path_mat = (Animal() & key).fetch1('anim_name', 'anim_path_raw', 'anim_path_mat')\n",
    "        dir_names = os.listdir(anim_path_raw)\n",
    "        for dir_name in dir_names:\n",
    "            m = re.search('^{:s}(\\d*)$'.format(anim_name.lower()), dir_name)\n",
    "            if m:\n",
    "                day = int(m.groups()[0])\n",
    "                day_path_raw = os.path.join(anim_path_raw, dir_name)\n",
    "                times_path = os.path.join(day_path_raw, 'times.mat')\n",
    "                if os.path.isfile(times_path):\n",
    "                    times_mat = loadmat(times_path)\n",
    "                    time_ranges = times_mat['ranges']\n",
    "                    day_start_time_nspike = time_ranges[0][0]\n",
    "                    day_end_time_nspike = time_ranges[0][1]\n",
    "                    day_start_time_sec = day_start_time_nspike/10000\n",
    "                    day_end_time_sec = day_end_time_nspike/10000\n",
    "                    self.insert1({'anim_name': anim_name,\n",
    "                                  'day': day,\n",
    "                                  'day_path_raw': day_path_raw,\n",
    "                                  'day_start_time_sec': day_start_time_nspike,\n",
    "                                  'day_end_time_sec': day_end_time_nspike,\n",
    "                                  'day_start_time_nspike': day_start_time_sec,\n",
    "                                  'day_end_time_nspike': day_end_time_sec})\n",
    "                else:\n",
    "                    # Missing times.mat means data folder was not processed for spike sorting (matclust)\n",
    "                    pass\n",
    "\n",
    "@schema\n",
    "class Epoch(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Day\n",
    "    epoch_id: tinyint\n",
    "    ---\n",
    "    epoch_name: varchar(50)\n",
    "    epoch_time_str: varchar(50)\n",
    "    epoch_start_time_sec: float\n",
    "    epoch_end_time_sec: float\n",
    "    epoch_start_time_nspike: int\n",
    "    epoch_end_time_nspike: int\n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        anim_name, day, day_path_raw = (Animal() * (Day() & key)).fetch1('anim_name', 'day', 'day_path_raw')\n",
    "        try:\n",
    "            times_mat = loadmat(os.path.join(day_path_raw, 'times.mat'))\n",
    "            time_ranges = times_mat['ranges']\n",
    "            names = times_mat['names']\n",
    "            for epoch_id, epoch_time_range in enumerate(time_ranges[1:]):\n",
    "                epoch_start_time_nspike = epoch_time_range[0]\n",
    "                epoch_end_time_nspike = epoch_time_range[1]\n",
    "                epoch_start_time_sec = epoch_start_time_nspike/10000\n",
    "                epoch_end_time_sec = epoch_end_time_nspike/10000\n",
    "                name_entry = names[epoch_id + 1][0][0]\n",
    "                name_re = re.search('\\d*\\s*(\\w*)\\s*([0-9:\\-_]*)$', name_entry)\n",
    "                if name_re:\n",
    "                    epoch_name = name_re.groups()[0]\n",
    "                    epoch_time_str = name_re.groups()[1]\n",
    "                    self.insert1({'anim_name': anim_name,\n",
    "                                  'day': day, \n",
    "                                  'epoch_id': epoch_id, \n",
    "                                  'epoch_name': epoch_name,\n",
    "                                  'epoch_time_str': epoch_time_str,\n",
    "                                  'epoch_start_time_sec': epoch_start_time_sec,\n",
    "                                  'epoch_end_time_sec':epoch_start_time_sec,\n",
    "                                  'epoch_start_time_nspike': epoch_start_time_nspike,\n",
    "                                  'epoch_end_time_nspike': epoch_end_time_nspike\n",
    "                                 })\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            raise CorruptData('Missing {:s}.'.format((os.path.join(day_path_raw, 'times.mat'))))\n",
    "    \n",
    "@schema\n",
    "class Tetrode(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Animal\n",
    "    tet_id: tinyint\n",
    "    ---\n",
    "    tet_hemisphere: varchar(50)\n",
    "    \"\"\"\n",
    "    def make(self, key):\n",
    "        anim_name, anim_path_mat = (Animal() & key).fetch1('anim_name', 'anim_path_mat')\n",
    "        mat = loadmat(os.path.join(anim_path_mat, 'bontetinfo.mat'))\n",
    "        tet = {}\n",
    "        for tet_days in mat['tetinfo'][0]:\n",
    "            if len(tet_days[0]) > 0:\n",
    "                for tet_epochs in tet_days[0]:\n",
    "                    for tet_id, tet_epoch in enumerate(tet_epochs[0]):\n",
    "                        if len(tet_epoch[0]) > 0:\n",
    "                            tet_entry = tet.setdefault(tet_id+1, {})\n",
    "                            tet_entry_hemi_list = tet_entry.setdefault('hemisphere', [])\n",
    "                            try:\n",
    "                                tet_hemi = tet_epoch[0][0]['hemisphere'][0]\n",
    "                            except ValueError:\n",
    "                                tet_hemi = None\n",
    "                            tet_entry_hemi_list.append(tet_hemi)\n",
    "\n",
    "        for tet_id, tet_entries in tet.items():\n",
    "            tet_hemi = tet_entries['hemisphere']\n",
    "            tet_hemi_set = set(tet_hemi)\n",
    "            if len(tet_hemi_set) == 1:\n",
    "                tet_hemisphere = list(tet_hemi_set)[0]\n",
    "                if tet_hemisphere is None:\n",
    "                    tet_hemisphere = ''\n",
    "                self.insert1({'anim_name': anim_name,\n",
    "                              'tet_id': tet_id,\n",
    "                              'tet_hemisphere': tet_hemisphere\n",
    "                             })\n",
    "            else:\n",
    "                warnings.warn(\"Tetrode {:d} doesn't have exactly 1 type for hemisphere entry: {:s}\".format(tet_id, str(tet_hemi_set)))\n",
    "\n",
    "\n",
    "@schema\n",
    "class TetrodeEpoch(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> Tetrode\n",
    "    -> Epoch\n",
    "    ---\n",
    "    tet_depth = NULL: int\n",
    "    tet_num_cells = NULL: int\n",
    "    tet_area = NULL: varchar(50)\n",
    "    tet_subarea = NULL: varchar(50)\n",
    "    tet_near_ca2 = NULL: tinyint       # boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, suppress_missing_print=False, arg=None):\n",
    "        self.suppress_missing_print = suppress_missing_print\n",
    "        super().__init__(arg)\n",
    "    \n",
    "    def _process_missing_field(self, field, key, suppress_missing_print):\n",
    "        if(not suppress_missing_print):\n",
    "             print(self._form_missing_str(field, key))\n",
    "        self._save_missing_entry(field, key)\n",
    "    \n",
    "    def _form_missing_str(self, field, key):\n",
    "        missing_str = ('Missing animal {:s}, day {:d}, epoch_id {:d}, tet_id {:d}: {:s}'.\n",
    "                       format(key['anim_name'], key['day'], key['epoch_id'], key['tet_id'], field))\n",
    "        \n",
    "        return missing_str\n",
    "    \n",
    "    def _save_missing_entry(self, field, key):\n",
    "        try:\n",
    "            self.missing_entries.append((key['anim_name'], key['day'], key['epoch_id'], key['tet_id'], field))\n",
    "        except AttributeError:\n",
    "            self.missing_entries = []\n",
    "            self.missing_entries.append((key['anim_name'], key['day'], key['epoch_id'], key['tet_id'], field))\n",
    "    \n",
    "    def make(self, key):\n",
    "        anim_name, anim_path_mat = (Animal() & key).fetch1('anim_name', 'anim_path_mat')\n",
    "        try:\n",
    "            mat = self.anim_tet_infos[anim_name]\n",
    "        except AttributeError:\n",
    "            self.anim_tet_infos = {}\n",
    "            mat = loadmat(os.path.join(anim_path_mat, 'bontetinfo.mat'))\n",
    "            self.anim_tet_infos[anim_name] = mat\n",
    "        except KeyError:\n",
    "            mat = loadmat(os.path.join(anim_path_mat, 'bontetinfo.mat'))\n",
    "            self.anim_tet_infos[anim_name] = mat            \n",
    "            \n",
    "        try:\n",
    "            tet_epoch_data = mat['tetinfo'][0][key['day']-1][0][key['epoch_id']][0][key['tet_id']][0]\n",
    "\n",
    "            # if mat cell is empty, skip insert\n",
    "            if tet_epoch_data.size > 0:\n",
    "                try:\n",
    "                    key['tet_depth'] = tet_epoch_data['depth'][0][0][0][0][0]\n",
    "                except (ValueError, IndexError):\n",
    "                    self._process_missing_field('\"tet_depth\"', key, self.suppress_missing_print)\n",
    "                    # print(key)\n",
    "                    # leave entry out\n",
    "                    pass\n",
    "                    # key['tet_depth'] = None\n",
    "                try:\n",
    "                    key['tet_num_cells'] = tet_epoch_data['numcells'][0][0][0]\n",
    "                except (ValueError, IndexError):\n",
    "                    self._process_missing_field('\"tet_num_cells\"', key, self.suppress_missing_print)\n",
    "                    # print(key)\n",
    "                    # leave entry out\n",
    "                    pass\n",
    "                    # key['tet_num_cells'] = None\n",
    "                try:\n",
    "                    key['tet_area'] = tet_epoch_data['area'][0][0]\n",
    "                except (ValueError, IndexError):\n",
    "                    self._process_missing_field('\"tet_area\"', key, self.suppress_missing_print)\n",
    "                    # print(key)\n",
    "                    # leave entry out\n",
    "                    pass\n",
    "                    # key['tet_area'] = None\n",
    "                try:\n",
    "                    key['tet_subarea'] = tet_epoch_data['subarea'][0][0]\n",
    "                except (ValueError, IndexError):\n",
    "                    self._process_missing_field('\"tet_subarea\"', key, self.suppress_missing_print)\n",
    "                    # print(key)\n",
    "                    # leave entry out\n",
    "                    pass\n",
    "                    # key['tet_subarea'] = None\n",
    "                try:\n",
    "                    key['tet_near_ca2'] = tet_epoch_data['nearCA2'][0][0][0]\n",
    "                except (ValueError, IndexError):\n",
    "                    self._process_missing_field('\"tet_near_ca2\"', key, self.suppress_missing_print)\n",
    "                    # print(key)\n",
    "                    # leave entry out\n",
    "                    pass\n",
    "                    # key['tet_near_ca2'] = None\n",
    "                self.insert1(key)\n",
    "        except (ValueError, IndexError):\n",
    "            self._process_missing_field('entire tetrode', key, self.suppress_missing_print)\n",
    "            # print(key)\n",
    "            pass\n",
    "\n",
    "@schema\n",
    "class LFP(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> TetrodeEpoch\n",
    "    ---\n",
    "    lfp_path_raw_part: varchar(200)\n",
    "    lfp_path_raw_abs: varchar(200)\n",
    "    lfp_path_eeg_part: varchar(200)\n",
    "    lfp_path_eeg_abs: varchar(200)\n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        print (key)\n",
    "        display((Animal() * Tetrode()) & key)\n",
    "     \n",
    "@schema\n",
    "class RippleInterval(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Epoch\n",
    "    algorithm: varchar(20)\n",
    "    ---\n",
    "    part_path: varchar(200)\n",
    "    path_abs: varchar(200)\n",
    "    \"\"\"\n",
    "    \n",
    "    class LFPSource(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> LFP\n",
    "        -> RippleInterval\n",
    "        ---\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        print(key)\n",
    "\n",
    "@schema\n",
    "class RawSpikes(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> TetrodeEpoch\n",
    "    ---\n",
    "    raw_spike_path: varchar(200)\n",
    "    \"\"\"\n",
    "\n",
    "@schema\n",
    "class Position(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Epoch\n",
    "    ---\n",
    "    pos_path: varchar(200)\n",
    "    \"\"\"\n",
    "\n",
    "@schema\n",
    "class LinearPosition(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Position\n",
    "    ---\n",
    "    lin_pos_path: varchar(200)\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = Day()\n",
    "epoch = Epoch()\n",
    "tet = Tetrode()\n",
    "tet_ep = TetrodeEpoch()\n",
    "lfp = LFP()\n",
    "rip = RippleInterval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tet_ep.anim_tet_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "anim = Animal()\n",
    "anim.insert1({'anim_name': 'Bond', 'anim_path_raw': '/opt/data/daliu/other/mkarlsso/bond/', \n",
    "              'anim_path_mat': '/opt/data/daliu/other/mkarlsso/Bon/'})\n",
    "display(anim)\n",
    "day = Day()\n",
    "day.populate()\n",
    "display(day)\n",
    "epoch = Epoch()\n",
    "epoch.populate()\n",
    "display(epoch)\n",
    "tet = Tetrode()\n",
    "tet.populate()\n",
    "display(tet)\n",
    "tet_ep = TetrodeEpoch(suppress_missing_print=True)\n",
    "tet_ep.populate()\n",
    "display(tet_ep)\n",
    "lfp = LFP()\n",
    "rip = RippleInterval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.ERD(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}